{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import load_runs\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_runs)\n",
    "DATA_PREP_FOLDER = './intermediate_results/data_prep_logistic'\n",
    "\n",
    "lm = load_runs.load_logistic_prep(DATA_PREP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    5\n",
      "2    4\n",
      "3    3\n",
      "4    1\n",
      "Name: index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/serial_chain/telephone-analysis-public/load_runs.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_runs = pd.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "all_runs = load_runs.load_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_words = all_runs['gold_candidate_transcription'][1:]\n",
    "user_words = all_runs['user_candidate_transcription'][1:]\n",
    "\n",
    "# Skip the first entry, \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(true_words)) # What to do? There are indeed repeats so checking will be harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load editTable information from Prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "if not exists(WORD_CHANGES_FOLDER):\n",
    "    os.makedirs(WORD_CHANGES_FOLDER)\n",
    "    \n",
    "substitution_df = pd.read_csv(join(WORD_CHANGES_FOLDER, 'edit_substitutions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the editTables word substitution yield is kind of low:\n",
    "\n",
    "22482 entries were matches\n",
    "3135 entries were insertions\n",
    "3442 entries were deletions\n",
    "1366 entries were substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of single substitution sentences: 522\n"
     ]
    }
   ],
   "source": [
    "off_by_one_sub = []\n",
    "\n",
    "def check_single_change(entry):\n",
    "    sent = entry['sentence'].split()\n",
    "    resp = entry['response'].split()\n",
    "    \n",
    "    filler_text = '<FILLER>'\n",
    "    sent[int(entry['sCounter'])] = filler_text\n",
    "    resp[int(entry['rCounter'])] = filler_text\n",
    "    \n",
    "    return sent == resp # Then?\n",
    "\n",
    "\n",
    "def test_check_single_change():\n",
    "    neg_case = check_single_change(substitution_df.iloc[0])\n",
    "    pos_case = check_single_change(substitution_df.iloc[12])\n",
    "\n",
    "    print(f'Neg case: {neg_case}')\n",
    "    print(f'Pos case: {pos_case}') # This works. Now run this on everything\n",
    "\n",
    "    \n",
    "# Run on the entire dataframe?\n",
    "\n",
    "ok_sentences = []\n",
    "for i in range(len(substitution_df)):\n",
    "    if check_single_change(substitution_df.iloc[i]):\n",
    "        ok_sentences.append(i)\n",
    "        \n",
    "print(f'Number of single substitution sentences: {len(ok_sentences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scoring per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results of scoring per model\n",
    "\n",
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "word_change_prob_df = join(WORD_CHANGES_FOLDER, 'word_changes_prob.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telephone-env-3",
   "language": "python",
   "name": "telephone-env-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
