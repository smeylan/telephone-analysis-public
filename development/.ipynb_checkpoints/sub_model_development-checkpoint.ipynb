{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development, quick analyses for violin plot related code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = './intermediate_results/new_models_probs'\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertForMaskedLM, BertTokenizer, BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "os.chdir('/home/nwong/chompsky/serial_chain/telephone-analysis-public')\n",
    "\n",
    "from new_models import prep_probs, model_score_funcs, align_prep_words, model_score_utils\n",
    "from new_models import in_progress\n",
    "\n",
    "from new_models import sub_analysis\n",
    "\n",
    "import importlib\n",
    "import load_runs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "For model: bert, length: 3193\n",
      "gpt2_normal\n",
      "For model: gpt2_normal, length: 3193\n",
      "bart\n",
      "For model: bart, length: 3193\n",
      "gpt2_medium\n",
      "For model: gpt2_medium, length: 3193\n",
      "0    0\n",
      "1    5\n",
      "2    4\n",
      "3    3\n",
      "4    1\n",
      "Name: index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/serial_chain/telephone-analysis-public/load_runs.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_runs = pd.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importlib.reload(prep_probs)\n",
    "\n",
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "if not exists(WORD_CHANGES_FOLDER):\n",
    "    os.makedirs(WORD_CHANGES_FOLDER)\n",
    "    \n",
    "substitution_df = pd.read_csv(join(WORD_CHANGES_FOLDER, 'edit_substitutions.csv'))\n",
    "\n",
    "tokenizers = {\n",
    "    'gpt2': GPT2Tokenizer.from_pretrained('gpt2'),\n",
    "    'bert': BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\"),\n",
    "    'bart': BartTokenizer.from_pretrained(\"facebook/bart-base\"),\n",
    "}\n",
    "\n",
    "PROB_DF_PATH = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/new_models_probs'\n",
    "raw_probs = {}\n",
    "for model_name in ['bert', 'gpt2_normal', 'bart', 'gpt2_medium']:\n",
    "    print(model_name)\n",
    "    raw_probs[model_name] = prep_probs.load_word_scores(model_name, PROB_DF_PATH, give_probs = True)\n",
    "    print(f'For model: {model_name}, length: {len(raw_probs[model_name])}')\n",
    "\n",
    "DATA_PREP_FOLDER = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/data_prep_logistic' # What is meant by this path?\n",
    "lm = prep_probs.load_postprocessed_logistic_prep_scores(DATA_PREP_FOLDER)\n",
    "\n",
    "all_runs = load_runs.load_runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for correctness of position of extraction/the softmax extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_mask_words(scores, sentence, tokenizer):\n",
    "    \"\"\"\n",
    "    raw_scores = a (vocabulary,) tensor of selected softmax values for a pre-selected position.\n",
    "    mask_idx, the position to select for analysis.\n",
    "    \n",
    "    sentence = the prefix to do the prediction on\n",
    "    tokenizer = BERT/BART tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # It should intake the raw scores itself.\n",
    "    score_vals, word_idxs = torch.sort(scores, descending = True)\n",
    "    words = tokenizer.convert_ids_to_tokens(word_idxs)\n",
    "\n",
    "    print(f\"Reporting most likely tokens to complete '{sentence}' in descending order\")\n",
    "\n",
    "    num_report = 20\n",
    "\n",
    "    score_df = pd.DataFrame.from_dict({\n",
    "      'Word': words,\n",
    "      'Score value': list(map(lambda x : round(x, 5), score_vals.numpy().tolist()))\n",
    "      })\n",
    "\n",
    "    return score_df[:num_report]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will compare the user transcription scored softmax against the ones produced by the new code from predicting from editTables\n",
    "\n",
    "\n",
    "Since the model score utils function was generally checked for correctness\n",
    "\n",
    "will just check the user transcription, since the arguments/function for response are parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scores that you saved from the main run.\n",
    "\n",
    "importlib.reload(prep_probs)\n",
    "\n",
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "all_changes_probs = prep_probs.load_word_changes(WORD_CHANGES_FOLDER)\n",
    "\n",
    "\n",
    "# Load the original score from the right case\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "\n",
    "print('For the \"predicting at\" printout, here I am only checking sWord, which is the first printout.')\n",
    "\n",
    "module_dict = {\n",
    "    'gpt2_normal': model_score_funcs.get_gpt2_modules,\n",
    "    'gpt2_medium': model_score_funcs.get_gpt2_modules,\n",
    "    'bert': model_score_funcs.get_bert_modules,\n",
    "    'bart': model_score_funcs.get_bart_modules,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_runs_idx_from_sub_idx(case_sentence):\n",
    "    return list(all_runs['user_candidate_transcription']).index(case_sentence)\n",
    "\n",
    "def report(case_idx, df_entry, this_word, raw_prob, new_prob):\n",
    "    this_report = f\"Mismatch in probabilities for entry {case_idx}.\"\n",
    "    this_report += f\"\\n\\t Word change original prob: {new_prob}\"\n",
    "    this_report += f\"\\n\\t List of probs from precomputed, prob entry: {raw_prob}\"\n",
    "    this_report += f\"\\n\\t Word of interest: {this_word}\"\n",
    "    this_report += f\"\\n\\t{df_entry}\"\n",
    "    return this_report\n",
    "    \n",
    "def compare_probs_model_case_idx(case_idx, model_name, this_model, this_tokenizer, this_prefix_func):\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks each of the sentences in all_runs to see\n",
    "    if the newly computed probabilities and the old ones from new_model_runs.py\n",
    "    match, as a sanity check\n",
    "    \"\"\"\n",
    "\n",
    "    df = all_changes_probs[model_name]\n",
    "    \n",
    "    this_df_entry = df.iloc[case_idx]\n",
    "    sentence_idx = get_all_runs_idx_from_sub_idx(this_df_entry['sentence'])\n",
    "    # Above: use the unprepped version to index correctly into all_runs.csv\n",
    "    \n",
    "    case_sentence = model_score_utils.prepSentence(this_df_entry['sentence'])\n",
    "    \n",
    "    # Above: It's important that prepSentence is used on all sentence calculations.\n",
    "    # For example, in case_idx = 245, not using prepSentence will result in lowercase \"failure\", which tokenizes as \"fail/ure\"\n",
    "    # However, prepSentence will make failure \"Failure\", which will not break in tokenization.\n",
    "    # This will change which word index you extract from as the \"true index\".\n",
    "\n",
    "    # Get the word change csv probability for this word\n",
    "    word_change_orig_prob = this_df_entry['orig_prob']\n",
    "\n",
    "    # Get the precomputed probability for this word from the raw \"run model save\" DataFrames\n",
    "    # in the long running computation\n",
    "\n",
    "    # This is to index into the right df from above\n",
    "    # 5/31 Indexing: https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-in-a-list\n",
    "    \n",
    "    orig_scores = raw_probs[model_name if model_name != 'gpt2' else model_name + '_normal'][sentence_idx]\n",
    "\n",
    "    # This is to change the sCounter to account for broken word tokenization in the original dataframes\n",
    "    # Specifically, relocated_idx is the final index position of the target word\n",
    "    # in the original raw probability DFs.\n",
    "    #      There is no need to adjust this index for CLS, etc. because CLS is not present in the dataframe\n",
    "    #      And the index is found using the dataframe directly.\n",
    "    relocated_idx = sub_analysis.find_true_token_position(case_sentence, this_df_entry['sWord'], int(this_df_entry['sCounter']), this_tokenizer)\n",
    "\n",
    "    # If the sWord was tokenizer-broken then it should mark it as such in the new dataframe\n",
    "    if relocated_idx == -2: \n",
    "        # Below assert checks to make sure that the target word really isn't in the tokenized list\n",
    "        assert not this_df_entry['sWord'] in orig_scores['word'], '{}, {}'.format(orig_scores['word'], this_df_entry['sWord'])\n",
    "        \n",
    "        word_change_has_nan = pd.isnull(word_change_orig_prob)\n",
    "        assert word_change_has_nan, 'Did not mark broken word as NaN probability'\n",
    "        \n",
    "        return None\n",
    "\n",
    "    this_word = this_df_entry['sWord']\n",
    "\n",
    "    \n",
    "    prior_prob_calculation_df = orig_scores.iloc[relocated_idx]\n",
    "\n",
    "    raw_orig_prob = prior_prob_calculation_df['prob']\n",
    "\n",
    "    # Compare the two computations to each other.\n",
    "    if abs(word_change_orig_prob - raw_orig_prob) > 1e-6:\n",
    "        print(report(case_idx, this_df_entry, this_word, raw_orig_prob, word_change_orig_prob))\n",
    "        print('***** RELOCATED IDX **** ', relocated_idx)\n",
    "        print(orig_scores)\n",
    "        mismatches[model_name].append((case_idx, this_word, word_change_orig_prob, orig_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each nonfiction book has a call number on its spine\n",
      "From the new dfs 0.043548859655857086\n",
      "From the old dfs        word      prob\n",
      "0      Each  0.000269\n",
      "1      Ġnon  0.000262\n",
      "2   fiction  0.011790\n",
      "3     Ġbook  0.438744\n",
      "4      Ġhas  0.057975\n",
      "5        Ġa  0.289296\n",
      "6     Ġcall  0.000068\n",
      "7   Ġnumber  0.000363\n",
      "8       Ġon  0.043549\n",
      "9      Ġits  0.095197\n",
      "10   Ġspine  0.051601\n"
     ]
    }
   ],
   "source": [
    "def run_sub_analysis_idx(case_idx, model_name):\n",
    "    \"\"\"\n",
    "    Useful for running the function directly for print statements\n",
    "    \"\"\"\n",
    "    \n",
    "    df = all_changes_probs[model_name].iloc[case_idx]\n",
    "    raw_sentence = df['sentence']\n",
    "    word = df['sWord']\n",
    "    position = df['sCounter']\n",
    "    model, tokenizer, prefix_func = module_dict[model_name]()\n",
    "    \n",
    "    result = sub_analysis.process_single_substitution(raw_sentence, word, position, model, tokenizer, prefix_func, verifying = False)\n",
    "    return result\n",
    "\n",
    "shift_index = 246\n",
    "norm_index = 0\n",
    "\n",
    "#this_case_index = shift_index\n",
    "this_case_index = norm_index\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "#compare_probs_model_case_idx(246, 'gpt2_normal')\n",
    "tdf = all_changes_probs['gpt2_normal'].iloc[this_case_index]\n",
    "this_sentence = tdf['sentence']\n",
    "print(this_sentence)\n",
    "result = run_sub_analysis_idx(this_case_index, 'gpt2_normal')\n",
    "\n",
    "print('From the new dfs', result)\n",
    "print('From the old dfs', raw_probs['gpt2_normal'][get_all_runs_idx_from_sub_idx(this_sentence)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING NEW MODEL SET: gpt2_normal\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n",
      "BEGINNING NEW MODEL SET: gpt2_medium\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING NEW MODEL SET: bert\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n",
      "BEGINNING NEW MODEL SET: bart\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n"
     ]
    }
   ],
   "source": [
    "# Check all of the positions and model names\n",
    "\n",
    "mismatches = defaultdict(list)\n",
    "\n",
    "for model_name in all_changes_probs:\n",
    "    \n",
    "    this_model, this_tokenizer, this_prefix_func = module_dict[model_name]()\n",
    "    print(f'BEGINNING NEW MODEL SET: {model_name}')\n",
    "\n",
    "    for case_idx in range(len(df)):\n",
    "        \n",
    "        if case_idx % 100 == 0: print(f'Current case idx: {case_idx} / {len(df)}')\n",
    "            \n",
    "        compare_probs_model_case_idx(case_idx, model_name, this_model, this_tokenizer, this_prefix_func)\n",
    "        \n",
    "assert not mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each non fiction book has a call number in its spine\n",
      "Reporting most likely tokens to complete 'Each nonfiction book has a call number .' in descending order\n",
      "         Word  Score value\n",
      "0           ,      0.15394\n",
      "1        Ġand      0.13827\n",
      "2           .      0.10464\n",
      "3       Ġthat      0.05881\n",
      "4         Ġon      0.05256\n",
      "5        Ġfor      0.03959\n",
      "6         Ġor      0.03700\n",
      "7         Ġto      0.03311\n",
      "8          Ġ(      0.02825\n",
      "9         Ġin      0.02520\n",
      "10        Ġat      0.02059\n",
      "11          :      0.01999\n",
      "12        Ġof      0.01606\n",
      "13    Ġlisted      0.01409\n",
      "14      Ġfrom      0.01196\n",
      "15     Ġwhich      0.01082\n",
      "16          ;      0.00875\n",
      "17  Ġattached      0.00770\n",
      "18      Ġwith      0.00694\n",
      "19        Ġso      0.00681\n"
     ]
    }
   ],
   "source": [
    "# GPT-2 prefix completion check\n",
    "# Directly passing in a prefix to the single substitution method.\n",
    "\n",
    "# Shows that GPT-2 is not good at predicting \"on\"\n",
    "#  despite reasonable results on \"It's time to go the\" case\n",
    "#  and also predicting \"Each nonfiction book has a call number on its\"\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "importlib.reload(model_score_utils)\n",
    "\n",
    "this_df = all_changes_probs['gpt2_normal'].iloc[2]\n",
    "model, tokenizer, prefix_func = model_score_funcs.get_gpt2_modules()\n",
    "new_sentence = this_df['sentence']\n",
    "\n",
    "print(new_sentence)\n",
    "\n",
    "orig_prob_results = sub_analysis.process_single_substitution(new_sentence,\n",
    "                                                             this_df['sWord'],\n",
    "                                                             this_df['sCounter'],\n",
    "                                                             model,\n",
    "                                                             tokenizer,\n",
    "                                                             prefix_func,\n",
    "                                                             verifying = True)\n",
    "\n",
    "orig_prob, orig_prob_all, all_probs = orig_prob_results\n",
    "\n",
    "\n",
    "tok = tokenizers['gpt2']\n",
    "\n",
    "test_sentence = model_score_utils.prepSentence(f\"each nonfiction book has a call number\")\n",
    "#test_sentence = f\"It's time to go to the \"\n",
    "this_tokens = tok.encode(test_sentence)\n",
    "this_pred_pos = len(this_tokens) - 2\n",
    "\n",
    "# The 0 is a filler index.\n",
    "prob_at_ground_truth, probs, _ = model_score_utils.get_model_probabilities(this_tokens, model, 0, this_pred_pos, verifying = True)\n",
    "result_df = report_mask_words(probs, test_sentence, tok)\n",
    "print(result_df)\n",
    "\n",
    "# It seems to be an inability to tolerate the sentence itself -- why?\n",
    "# Despite it working on the \"it's time to go to the\" case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the true token position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for correctness of substitution processing\n",
    "\n",
    "WORD_CHANGES_FOLDER = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/word_changes'\n",
    "\n",
    "substitution_df = pd.read_csv(join(WORD_CHANGES_FOLDER, 'edit_substitutions.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_true_token_pos_both(df_entry, model, tokenizer, prefix_func):\n",
    "    \n",
    "    # Need to check if these are 0 indexed?\n",
    "    \n",
    "    orig_loc = sub_analysis.find_true_token_position(df_entry['sentence'], df_entry['sWord'], int(df_entry['sCounter']), tokenizer)\n",
    "    edited_loc = sub_analysis.find_true_token_position(df_entry['response'], df_entry['rWord'], int(df_entry['rCounter']), tokenizer)\n",
    "    \n",
    "    return orig_loc, edited_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-aeca8740385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Handle cannot find case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_true_token_pos_both\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_score_funcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bert_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/model_score_funcs.py\u001b[0m in \u001b[0;36mget_bert_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#2/20: https://albertauyeung.github.io/2020/06/19/bert-tokenization.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased-whole-word-masking'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             )\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# Prune heads if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m_init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;31m# Slightly different from the TF version which uses truncated_normal for initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;31m# cf https://github.com/pytorch/pytorch/pull/5617\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# GPT-2 tests for find\n",
    "\n",
    "# Handle unchanged and changed case, GPT-2\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_gpt2_modules())\n",
    "assert result == (8,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_gpt2_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n",
    "\n",
    "\n",
    "# BERT tests for find\n",
    "\n",
    "# Handle unchanged and changed case, BERT\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_bert_modules())\n",
    "assert result == (7,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_bert_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n",
    "\n",
    "\n",
    "\n",
    "# BART tests for find\n",
    "\n",
    "# Handle unchanged and changed case, BART\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_bart_modules())\n",
    "assert result == (8,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_bart_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>code</th>\n",
       "      <th>sWord</th>\n",
       "      <th>rWord</th>\n",
       "      <th>sCounter</th>\n",
       "      <th>rCounter</th>\n",
       "      <th>sentence</th>\n",
       "      <th>response</th>\n",
       "      <th>sLeftSequence</th>\n",
       "      <th>rLeftSequence</th>\n",
       "      <th>sRightSequence</th>\n",
       "      <th>rRightSequence</th>\n",
       "      <th>input_subject</th>\n",
       "      <th>output_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>on</td>\n",
       "      <td>in</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>each nonfiction book has a call number on its ...</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>call number on</td>\n",
       "      <td>call number in</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>has</td>\n",
       "      <td>had</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>fiction book has</td>\n",
       "      <td>nonfiction book had</td>\n",
       "      <td>has a call</td>\n",
       "      <td>had a call</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>S</td>\n",
       "      <td>in</td>\n",
       "      <td>on</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>call number in</td>\n",
       "      <td>call number on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>12</td>\n",
       "      <td>twelve</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>each non fiction book had 12 numbers on its spine</td>\n",
       "      <td>each nonfiction book had twelve numbers on its...</td>\n",
       "      <td>book had 12</td>\n",
       "      <td>book had twelve</td>\n",
       "      <td>12 numbers on</td>\n",
       "      <td>twelve numbers on</td>\n",
       "      <td>dc02e8bc38234eed94e4e0cfbe083801</td>\n",
       "      <td>e1f5fb8bc21048cb8a50771b80eda39a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>numbers</td>\n",
       "      <td>notches</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>each non fiction book had twelve numbers on it...</td>\n",
       "      <td>each nonfiction book had twelve notches on its...</td>\n",
       "      <td>had twelve numbers</td>\n",
       "      <td>had twelve notches</td>\n",
       "      <td>numbers on its</td>\n",
       "      <td>notches on its</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>a575811edc0841b082724370f678d574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 code    sWord    rWord  sCounter  rCounter  \\\n",
       "0          11    S       on       in       7.0       8.0   \n",
       "1          11    S      has      had       4.0       3.0   \n",
       "2          12    S       in       on       8.0       7.0   \n",
       "3          13    S       12   twelve       5.0       4.0   \n",
       "4          13    S  numbers  notches       6.0       5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  each nonfiction book has a call number on its ...   \n",
       "1  each non fiction book has a call number in its...   \n",
       "2  each non fiction book has a call number in its...   \n",
       "3  each non fiction book had 12 numbers on its spine   \n",
       "4  each non fiction book had twelve numbers on it...   \n",
       "\n",
       "                                            response       sLeftSequence  \\\n",
       "0  each non fiction book has a call number in its...      call number on   \n",
       "1  each nonfiction book had a call number on its ...    fiction book has   \n",
       "2  each nonfiction book had a call number on its ...      call number in   \n",
       "3  each nonfiction book had twelve numbers on its...         book had 12   \n",
       "4  each nonfiction book had twelve notches on its...  had twelve numbers   \n",
       "\n",
       "         rLeftSequence  sRightSequence     rRightSequence  \\\n",
       "0       call number in    on its spine                NaN   \n",
       "1  nonfiction book had      has a call         had a call   \n",
       "2       call number on             NaN       on its spine   \n",
       "3      book had twelve   12 numbers on  twelve numbers on   \n",
       "4   had twelve notches  numbers on its     notches on its   \n",
       "\n",
       "                      input_subject                    output_subject  \n",
       "0                                 0  8cf6535ea0ae4addb28f5f90a2b13a7d  \n",
       "1  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc  \n",
       "2  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc  \n",
       "3  dc02e8bc38234eed94e4e0cfbe083801  e1f5fb8bc21048cb8a50771b80eda39a  \n",
       "4  53edaed0aee2422e96af6c0d3d636962  a575811edc0841b082724370f678d574  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 1\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', '[MASK]', 'a', 'call', 'number', 'in', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', '[MASK]', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 2\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 3\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'had', '[MASK]', 'numbers', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', '[MASK]', 'numbers', 'on', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 4\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'had', 'twelve', '[MASK]', 'on', 'its', 'spine', '[SEP]']\n",
      "Fragmented\n",
      "\n",
      "\n",
      "\n",
      "Entry 0\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "\n",
      "Entry 1\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook']\n",
      "\n",
      "Entry 2\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "\n",
      "Entry 3\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad']\n",
      "\n",
      "Entry 4\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', 'Ġtwelve']\n",
      "Fragmented\n",
      "\n",
      "\n",
      "\n",
      "Entry 0\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 1\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', '<mask>', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġin', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', '<mask>', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 2\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 3\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', '<mask>', 'Ġnumbers', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', '<mask>', 'Ġnumbers', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 4\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', 'Ġtwelve', '<mask>', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "Fragmented\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking prefix correctness with the true position finding\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_bert_modules())\n",
    "\n",
    "print(); print()\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_gpt2_modules())\n",
    "\n",
    "print(); print()\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_bart_modules())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking expected saving behavior for the single_substitution predictions and the edit saves.\n",
    "# Results saved on the prefix. These are just for debugging purposes.\n",
    "\n",
    "debug_save_results_folder = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/word_changes_prefix_only'\n",
    "debug_save_results_path = join(debug_save_results_folder, 'word_change_probs.csv')\n",
    "\n",
    "results_df = pd.read_csv(debug_save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>code</th>\n",
       "      <th>sWord</th>\n",
       "      <th>rWord</th>\n",
       "      <th>sCounter</th>\n",
       "      <th>rCounter</th>\n",
       "      <th>sentence</th>\n",
       "      <th>response</th>\n",
       "      <th>sLeftSequence</th>\n",
       "      <th>rLeftSequence</th>\n",
       "      <th>sRightSequence</th>\n",
       "      <th>rRightSequence</th>\n",
       "      <th>input_subject</th>\n",
       "      <th>output_subject</th>\n",
       "      <th>orig_prob</th>\n",
       "      <th>edited_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>on</td>\n",
       "      <td>in</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>each nonfiction book has a call number on its ...</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>call number on</td>\n",
       "      <td>call number in</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>0.350487</td>\n",
       "      <td>0.057322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>has</td>\n",
       "      <td>had</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>fiction book has</td>\n",
       "      <td>nonfiction book had</td>\n",
       "      <td>has a call</td>\n",
       "      <td>had a call</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "      <td>0.338602</td>\n",
       "      <td>0.007203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>S</td>\n",
       "      <td>in</td>\n",
       "      <td>on</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>call number in</td>\n",
       "      <td>call number on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.355695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>12</td>\n",
       "      <td>twelve</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>each non fiction book had 12 numbers on its spine</td>\n",
       "      <td>each nonfiction book had twelve numbers on its...</td>\n",
       "      <td>book had 12</td>\n",
       "      <td>book had twelve</td>\n",
       "      <td>12 numbers on</td>\n",
       "      <td>twelve numbers on</td>\n",
       "      <td>dc02e8bc38234eed94e4e0cfbe083801</td>\n",
       "      <td>e1f5fb8bc21048cb8a50771b80eda39a</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>numbers</td>\n",
       "      <td>notches</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>each non fiction book had twelve numbers on it...</td>\n",
       "      <td>each nonfiction book had twelve notches on its...</td>\n",
       "      <td>had twelve numbers</td>\n",
       "      <td>had twelve notches</td>\n",
       "      <td>numbers on its</td>\n",
       "      <td>notches on its</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>a575811edc0841b082724370f678d574</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1 code    sWord    rWord  sCounter  rCounter  \\\n",
       "0           0            11    S       on       in       7.0       8.0   \n",
       "1           1            11    S      has      had       4.0       3.0   \n",
       "2           2            12    S       in       on       8.0       7.0   \n",
       "3           3            13    S       12   twelve       5.0       4.0   \n",
       "4           4            13    S  numbers  notches       6.0       5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  each nonfiction book has a call number on its ...   \n",
       "1  each non fiction book has a call number in its...   \n",
       "2  each non fiction book has a call number in its...   \n",
       "3  each non fiction book had 12 numbers on its spine   \n",
       "4  each non fiction book had twelve numbers on it...   \n",
       "\n",
       "                                            response       sLeftSequence  \\\n",
       "0  each non fiction book has a call number in its...      call number on   \n",
       "1  each nonfiction book had a call number on its ...    fiction book has   \n",
       "2  each nonfiction book had a call number on its ...      call number in   \n",
       "3  each nonfiction book had twelve numbers on its...         book had 12   \n",
       "4  each nonfiction book had twelve notches on its...  had twelve numbers   \n",
       "\n",
       "         rLeftSequence  sRightSequence     rRightSequence  \\\n",
       "0       call number in    on its spine                NaN   \n",
       "1  nonfiction book had      has a call         had a call   \n",
       "2       call number on             NaN       on its spine   \n",
       "3      book had twelve   12 numbers on  twelve numbers on   \n",
       "4   had twelve notches  numbers on its     notches on its   \n",
       "\n",
       "                      input_subject                    output_subject  \\\n",
       "0                                 0  8cf6535ea0ae4addb28f5f90a2b13a7d   \n",
       "1  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc   \n",
       "2  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc   \n",
       "3  dc02e8bc38234eed94e4e0cfbe083801  e1f5fb8bc21048cb8a50771b80eda39a   \n",
       "4  53edaed0aee2422e96af6c0d3d636962  a575811edc0841b082724370f678d574   \n",
       "\n",
       "   orig_prob  edited_prob  \n",
       "0   0.350487     0.057322  \n",
       "1   0.338602     0.007203  \n",
       "2   0.057322     0.355695  \n",
       "3   0.002778     0.000954  \n",
       "4   0.005896          NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick dataset analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many sentences were affected by tokenization misalignments.\n",
    "# This will load the aligned versions of the results, where the broken words were taken out\n",
    "\n",
    "\n",
    "DATA_PREP_FOLDER = './intermediate_results/data_prep_logistic'\n",
    "lm = load_runs.load_logistic_prep(DATA_PREP_FOLDER)\n",
    "\n",
    "\n",
    "model_key = 'gpt2_normal'\n",
    "\n",
    "# Need to compare words. Should be enough to compare length of the two as a first pass.\n",
    "\n",
    "all_count = 0\n",
    "\n",
    "for model in transformer_names:\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    aligned_score_list = lm[model+'_scores']\n",
    "    raw_score_list = raw_scores[model]\n",
    "    assert len(aligned_score_list) == len(raw_score_list)\n",
    "    \n",
    "    \n",
    "    for i in range(len(aligned_score_list)):\n",
    "        if len(aligned_score_list[i]) != len(raw_score_list[i]):\n",
    "            count += 1\n",
    "    print(f'Model: {model}, Number of alignment length difference: {count} / {len(aligned_score_list)}')\n",
    "    all_count += count\n",
    "\n",
    "print(f'Total misalignment over all models: {all_count}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the editTables word substitution yield is kind of low:\n",
    "\n",
    "22482 entries were matches\n",
    "\n",
    "3135 entries were insertions\n",
    "\n",
    "3442 entries were deletions\n",
    "\n",
    "1366 entries were substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_by_one_sub = []\n",
    "\n",
    "def check_single_change(entry):\n",
    "    sent = entry['sentence'].split()\n",
    "    resp = entry['response'].split()\n",
    "    \n",
    "    filler_text = '<FILLER>'\n",
    "    sent[int(entry['sCounter'])] = filler_text\n",
    "    resp[int(entry['rCounter'])] = filler_text\n",
    "    \n",
    "    return sent == resp # Then?\n",
    "\n",
    "\n",
    "def test_check_single_change():\n",
    "    neg_case = check_single_change(substitution_df.iloc[0])\n",
    "    pos_case = check_single_change(substitution_df.iloc[12])\n",
    "\n",
    "    print(f'Neg case: {neg_case}')\n",
    "    print(f'Pos case: {pos_case}') # This works. Now run this on everything\n",
    "\n",
    "    \n",
    "# Run on the entire dataframe?\n",
    "\n",
    "ok_sentences = []\n",
    "for i in range(len(substitution_df)):\n",
    "    if check_single_change(substitution_df.iloc[i]):\n",
    "        ok_sentences.append(i)\n",
    "        \n",
    "print(f'Number of single substitution sentences: {len(ok_sentences)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telephone-env-3",
   "language": "python",
   "name": "telephone-env-3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
