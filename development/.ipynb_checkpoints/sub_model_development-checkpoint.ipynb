{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development, quick analyses for violin plot related code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = './intermediate_results/new_models_probs'\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertForMaskedLM, BertTokenizer, BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "os.chdir('/home/nwong/chompsky/serial_chain/telephone-analysis-public')\n",
    "\n",
    "from new_models import prep_probs, model_score_funcs, align_prep_words, model_score_utils\n",
    "\n",
    "from new_models import sub_analysis, sub_analysis_plots\n",
    "\n",
    "import importlib\n",
    "import load_runs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "For model: bert, length: 3193\n",
      "gpt2_normal\n",
      "For model: gpt2_normal, length: 3193\n",
      "bart\n",
      "For model: bart, length: 3193\n",
      "gpt2_medium\n",
      "For model: gpt2_medium, length: 3193\n",
      "0    0\n",
      "1    5\n",
      "2    4\n",
      "3    3\n",
      "4    1\n",
      "Name: index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwong/chompsky/serial_chain/telephone-analysis-public/load_runs.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_runs = pd.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importlib.reload(prep_probs)\n",
    "\n",
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "if not exists(WORD_CHANGES_FOLDER):\n",
    "    os.makedirs(WORD_CHANGES_FOLDER)\n",
    "    \n",
    "substitution_df = pd.read_csv(join(WORD_CHANGES_FOLDER, 'edit_substitutions.csv'))\n",
    "\n",
    "tokenizers = {\n",
    "    'gpt2': GPT2Tokenizer.from_pretrained('gpt2'),\n",
    "    'bert': BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\"),\n",
    "    'bart': BartTokenizer.from_pretrained(\"facebook/bart-base\"),\n",
    "}\n",
    "\n",
    "PROB_DF_PATH = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/new_models_probs'\n",
    "raw_probs = {}\n",
    "for model_name in ['bert', 'gpt2_normal', 'bart', 'gpt2_medium']:\n",
    "    print(model_name)\n",
    "    raw_probs[model_name] = prep_probs.load_word_scores(model_name, PROB_DF_PATH, give_probs = True)\n",
    "    print(f'For model: {model_name}, length: {len(raw_probs[model_name])}')\n",
    "\n",
    "DATA_PREP_FOLDER = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/data_prep_logistic' # What is meant by this path?\n",
    "lm = prep_probs.load_postprocessed_logistic_prep_scores(DATA_PREP_FOLDER)\n",
    "\n",
    "all_runs = load_runs.load_runs()\n",
    "\n",
    "\n",
    "module_dict = {\n",
    "    'gpt2_normal': model_score_funcs.get_gpt2_modules,\n",
    "    'gpt2_medium': model_score_funcs.get_gpt2_modules,\n",
    "    'bert': model_score_funcs.get_bert_modules,\n",
    "    'bart': model_score_funcs.get_bart_modules,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to see what's the proper way to add BOS?\n",
    "\n",
    "# Code from here\n",
    "\n",
    "# 6/2: https://github.com/huggingface/transformers/issues/1009\n",
    "# This claims you should add BOS before the sentence\n",
    "# 6/2: Another example adding BOS, EOS: \n",
    "# 6/2: https://github.com/huggingface/transformers/issues/3311\n",
    "# This claims the same.\n",
    "\n",
    "# You should not add space before first sentence:\n",
    "# https://discuss.huggingface.co/t/bpe-tokenizers-and-spaces-before-words/475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violin plot correctness checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  is_original_prob model_name     score\n",
      "2              Yes   high-low  0.301030\n",
      "4              Yes   high-low  0.221849\n",
      "5              Yes   high-low  0.154902\n",
      "2               No   high-low  1.000000\n",
      "4               No   high-low  0.698970\n",
      "5               No   high-low  0.522879\n",
      "0              Yes   low-high  1.000000\n",
      "2              Yes   low-high  0.698970\n",
      "0               No   low-high  0.301030\n",
      "2               No   low-high  0.221849\n",
      "Surprisal of high sequence: [0.30103    0.22184875 0.15490196]\n",
      "Surprisal of low sequence: [1.         0.69897    0.52287875]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  is_original_prob model_name  score\n",
      "2              Yes   high-low    0.5\n",
      "4              Yes   high-low    0.6\n",
      "5              Yes   high-low    0.7\n",
      "2               No   high-low    0.1\n",
      "4               No   high-low    0.2\n",
      "5               No   high-low    0.3\n",
      "0              Yes   low-high    0.1\n",
      "2              Yes   low-high    0.2\n",
      "0               No   low-high    0.5\n",
      "2               No   low-high    0.6\n",
      "Surprisal of high sequence: [0.30103    0.22184875 0.15490196]\n",
      "Surprisal of low sequence: [1.         0.69897    0.52287875]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(sub_analysis_plots)\n",
    "\n",
    "\n",
    "# This has been manually verified (the dataframe and its values, also reasonable plots for both plots)\n",
    "# Also manually verified after adding cases with one NaN but not both\n",
    "\n",
    "all_changes_probs_fake = {\n",
    "    'high-low': pd.DataFrame.from_records({'orig_prob' : [0.7, None, 0.5, None, 0.6, 0.7], 'edited_prob': [None, None, 0.1, None, 0.2, 0.3]}),\n",
    "    'low-high': pd.DataFrame.from_records({'orig_prob' : [0.1, None, 0.2], 'edited_prob': [0.5, 0.8, 0.6]}),\n",
    "}\n",
    "\n",
    "# Below is code taken from the violin notebook and is being tested here.\n",
    "\n",
    "for use_surprisal in [True, False]:\n",
    "    \n",
    "    all_model_dfs = sub_analysis_plots.gen_violin_plots(all_changes_probs_fake, use_surprisal)\n",
    "    \n",
    "    print(all_model_dfs)\n",
    "    print(f'Surprisal of high sequence: {-np.log10([0.5, 0.6, 0.7])}')\n",
    "    print(f'Surprisal of low sequence: {-np.log10([0.1, 0.2, 0.3])}')\n",
    "\n",
    "    # 6/1: https://seaborn.pydata.org/generated/seaborn.violinplot.html\n",
    "\n",
    "    score_type = 'surprisals' if use_surprisal else 'probabilities'\n",
    "    plt.title(f'Frequency of original and substituted word {score_type}')\n",
    "    sns.violinplot(\n",
    "        x = 'model_name', y = 'score',\n",
    "        data = all_model_dfs,\n",
    "        hue = 'is_original_prob',\n",
    "        palette = 'muted',\n",
    "        split = True\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching new substitution probabilities with new_model_run probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scores that you saved from the main run.\n",
    "\n",
    "importlib.reload(prep_probs)\n",
    "\n",
    "WORD_CHANGES_FOLDER = './intermediate_results/word_changes'\n",
    "all_changes_probs = prep_probs.load_word_changes(WORD_CHANGES_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs actually don't have to be paired to be correct -- is possible that you edit a word from/to one that's broken by a tokenizer.\n",
    "\n",
    "These entries should just be dropped in the violin analysis, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>code</th>\n",
       "      <th>sWord</th>\n",
       "      <th>rWord</th>\n",
       "      <th>sCounter</th>\n",
       "      <th>rCounter</th>\n",
       "      <th>sentence</th>\n",
       "      <th>response</th>\n",
       "      <th>sLeftSequence</th>\n",
       "      <th>rLeftSequence</th>\n",
       "      <th>sRightSequence</th>\n",
       "      <th>rRightSequence</th>\n",
       "      <th>input_subject</th>\n",
       "      <th>output_subject</th>\n",
       "      <th>orig_prob</th>\n",
       "      <th>edited_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>numbers</td>\n",
       "      <td>notches</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>each non fiction book had twelve numbers on it...</td>\n",
       "      <td>each nonfiction book had twelve notches on its...</td>\n",
       "      <td>had twelve numbers</td>\n",
       "      <td>had twelve notches</td>\n",
       "      <td>numbers on its</td>\n",
       "      <td>notches on its</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>a575811edc0841b082724370f678d574</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>dietitian</td>\n",
       "      <td>priest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a dietitian goes to college for at least four ...</td>\n",
       "      <td>a priest goes to college for at least four years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dietitian goes to</td>\n",
       "      <td>priest goes to</td>\n",
       "      <td>3418530188874362906071bff7b82f88</td>\n",
       "      <td>17aea24c08f1429c8fa43573f4342948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>fluff</td>\n",
       "      <td>hut</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>the horses are cold and need their fluff</td>\n",
       "      <td>the horses are cold and need their hut</td>\n",
       "      <td>need their fluff</td>\n",
       "      <td>need their hut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e1f5fb8bc21048cb8a50771b80eda39a</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>natures</td>\n",
       "      <td>nature</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>the horses are pulled on the natures path</td>\n",
       "      <td>the horses are pulled on the nature path</td>\n",
       "      <td>on the natures</td>\n",
       "      <td>on the nature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>821252d8660547b98b13f0103b19af8a</td>\n",
       "      <td>aec6a83b7a6f4297a2a5d2c6ac47be85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>three</td>\n",
       "      <td>greek</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>the iris accepts all light rings except three</td>\n",
       "      <td>the iris accepts all life beings except greek</td>\n",
       "      <td>rings except three</td>\n",
       "      <td>beings except greek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805b2dbf2fdc4b7da527a1990caa2cec</td>\n",
       "      <td>79898d5889764da58052ff63b6d18806</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1 code      sWord    rWord  sCounter  rCounter  \\\n",
       "4            4            13    S    numbers  notches       6.0       5.0   \n",
       "8            8             2    S  dietitian   priest       1.0       1.0   \n",
       "12          12            11    S      fluff      hut       7.0       7.0   \n",
       "14          14            11    S    natures   nature       6.0       6.0   \n",
       "22          22            11    S      three    greek       7.0       7.0   \n",
       "\n",
       "                                             sentence  \\\n",
       "4   each non fiction book had twelve numbers on it...   \n",
       "8   a dietitian goes to college for at least four ...   \n",
       "12           the horses are cold and need their fluff   \n",
       "14          the horses are pulled on the natures path   \n",
       "22      the iris accepts all light rings except three   \n",
       "\n",
       "                                             response       sLeftSequence  \\\n",
       "4   each nonfiction book had twelve notches on its...  had twelve numbers   \n",
       "8    a priest goes to college for at least four years                 NaN   \n",
       "12             the horses are cold and need their hut    need their fluff   \n",
       "14           the horses are pulled on the nature path      on the natures   \n",
       "22      the iris accepts all life beings except greek  rings except three   \n",
       "\n",
       "          rLeftSequence     sRightSequence  rRightSequence  \\\n",
       "4    had twelve notches     numbers on its  notches on its   \n",
       "8                   NaN  dietitian goes to  priest goes to   \n",
       "12       need their hut                NaN             NaN   \n",
       "14        on the nature                NaN             NaN   \n",
       "22  beings except greek                NaN             NaN   \n",
       "\n",
       "                       input_subject                    output_subject  \\\n",
       "4   53edaed0aee2422e96af6c0d3d636962  a575811edc0841b082724370f678d574   \n",
       "8   3418530188874362906071bff7b82f88  17aea24c08f1429c8fa43573f4342948   \n",
       "12  e1f5fb8bc21048cb8a50771b80eda39a  53edaed0aee2422e96af6c0d3d636962   \n",
       "14  821252d8660547b98b13f0103b19af8a  aec6a83b7a6f4297a2a5d2c6ac47be85   \n",
       "22  805b2dbf2fdc4b7da527a1990caa2cec  79898d5889764da58052ff63b6d18806   \n",
       "\n",
       "    orig_prob  edited_prob  \n",
       "4    0.000851          NaN  \n",
       "8         NaN     0.000227  \n",
       "12        NaN     0.000015  \n",
       "14        NaN     0.000019  \n",
       "22   0.001069          NaN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def check_nans_are_paired(df, quiet = True):\n",
    "    \n",
    "    # Let xor results be bad locations\n",
    "    \n",
    "    xor_result = (df['orig_prob'].isna() ^ df['edited_prob'].isna())\n",
    "    result = all(~xor_result)\n",
    "\n",
    "    sel = df[xor_result] \n",
    "            \n",
    "    return result, sel\n",
    "\n",
    "\n",
    "# Below are checks for the check.\n",
    "\n",
    "neg = pd.DataFrame.from_records({'orig_prob' : [1, 2, None, 3, None], 'edited_prob' : [1, 2, -1, 3, None]})\n",
    "pos = pd.DataFrame.from_records({'orig_prob' : [15, 2, -1, 3, None], 'edited_prob' : [1, 2, -1, 3, None]})\n",
    "assert not check_nans_are_paired(neg)[0]\n",
    "assert check_nans_are_paired(pos)[0]\n",
    "\n",
    "# Below actually checks the data\n",
    "# The data is not actually fully paired -- it may not be appropriate to assume that NaNs are always paired\n",
    "# If an edit results in an edit to a breakable word \n",
    "cases_sels = {df_name : check_nans_are_paired(df, quiet = False)[1]\n",
    "              for df_name, df in all_changes_probs.items()}\n",
    "\n",
    "cases_sels['gpt2_normal'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_mask_words(scores, sentence, tokenizer):\n",
    "    \"\"\"\n",
    "    raw_scores = a (vocabulary,) tensor of selected softmax values for a pre-selected position.\n",
    "    mask_idx, the position to select for analysis.\n",
    "    \n",
    "    sentence = the prefix to do the prediction on\n",
    "    tokenizer = BERT/BART tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # It should intake the raw scores itself.\n",
    "    score_vals, word_idxs = torch.sort(scores, descending = True)\n",
    "    words = tokenizer.convert_ids_to_tokens(word_idxs)\n",
    "\n",
    "    print(f\"Reporting most likely tokens to complete '{sentence}' in descending order\")\n",
    "\n",
    "    num_report = 20\n",
    "\n",
    "    score_df = pd.DataFrame.from_dict({\n",
    "      'Word': words,\n",
    "      'Score value': list(map(lambda x : round(x, 5), score_vals.numpy().tolist()))\n",
    "      })\n",
    "\n",
    "    return score_df[:num_report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking case idx: 0 and model: gpt2_normal\n",
      "['<|endoftext|>', 'Each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "Checking case idx: 8 and model: gpt2_normal\n",
      "['<|endoftext|>', 'A']\n",
      "Checking case idx: 0 and model: gpt2_medium\n",
      "['<|endoftext|>', 'Each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "Checking case idx: 8 and model: gpt2_medium\n",
      "['<|endoftext|>', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking case idx: 0 and model: bert\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '.', '[SEP]']\n",
      "Checking case idx: 8 and model: bert\n",
      "['[CLS]', 'a', '[MASK]', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.', '[SEP]']\n",
      "Checking case idx: 0 and model: bart\n",
      "['<s>', 'Each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', 'Ġ.', '</s>']\n",
      "Checking case idx: 8 and model: bart\n",
      "['<s>', 'A', '<mask>', 'Ġgoes', 'Ġto', 'Ġcollege', 'Ġfor', 'Ġat', 'Ġleast', 'Ġfour', 'Ġyears', 'Ġ.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Checking for the correctness of edited probabilities \n",
    "\n",
    "# Checking that directly asking the model for the answer gives the same thing as asking the function\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "\n",
    "def run_edit_prob_match(this_case_idx, this_model_df, this_model, this_tokenizer, this_prefix_func):\n",
    "        \n",
    "    this_case_entry = this_model_df.iloc[this_case_idx]\n",
    "\n",
    "    _, edited_prob_result = sub_analysis.process_substitution_entry(this_case_entry,\n",
    "                                                       this_model, this_tokenizer, this_prefix_func)\n",
    "    true_idx = sub_analysis.find_true_token_position(this_case_entry['response'],\n",
    "                                                     this_case_entry['rWord'],\n",
    "                                                     int(this_case_entry['rCounter']),\n",
    "                                                     this_tokenizer)\n",
    "\n",
    "    # You need to add one to the true_idx for the ground truth index because the tokens includes CLS,\n",
    "    # but the true_idx finding does not.\n",
    "    # However, GPT-2 will predict what follows the prefix, others will predict the mask.\n",
    "\n",
    "    this_prefix, tokens = this_prefix_func(model_score_utils.prepSentence(this_case_entry['response']), this_tokenizer, positions = [true_idx + 1])\n",
    "\n",
    "    print(this_tokenizer.convert_ids_to_tokens(this_prefix[0]))\n",
    "\n",
    "    logit_position = true_idx + 1 if not 'gpt2' in model_name else true_idx\n",
    "    # The else is because +1 for CLS, -1 for logit adjustment.\n",
    "    \n",
    "    # True idx and logit pos, as well as prefixes, are as expected for GPT-2.\n",
    "    # The same for BERT and BART.\n",
    "\n",
    "    direct_prob = model_score_utils.get_model_probabilities(this_prefix, this_model, tokens[true_idx + 1], logit_position)\n",
    "\n",
    "    if abs(edited_prob_result - direct_prob) > 1e-6:\n",
    "        print(f'Failed on case idx: {case_idx} and model: {model_name}')\n",
    "        print(direct_prob)\n",
    "        print(edited_prob_result)\n",
    "        \n",
    "\n",
    "case_idxs = [0, 8]\n",
    "\n",
    "# These are both cases where the token can be found in the prefix.\n",
    "# For cases where this is not the case, see the orig prob tests\n",
    "\n",
    "for model_name in ['gpt2_normal', 'gpt2_medium', 'bert', 'bart']:\n",
    "    model_args = module_dict[model_name]()\n",
    "    \n",
    "    model_df = all_changes_probs[model_name]\n",
    "    \n",
    "    for case_idx in case_idxs:\n",
    "        print(f'Checking case idx: {case_idx} and model: {model_name}')\n",
    "        run_edit_prob_match(case_idx, model_df, *model_args)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check to make sure the +1, -1 indexing to the model softmax extraction makes sense.\n",
    "# I copy my code from process_single_substitution to check the indexing.\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "\n",
    "\n",
    "def test_softmax_extraction_indexing(model_name, which_test):\n",
    "    \n",
    "    tests = {\n",
    "        'book' : (\"each nonfiction book has a call number on its spine\", 'book', 2),\n",
    "        'go' : (\"it is time to go to the museum\", 'museum', 7),\n",
    "        'king' : (\"each nonfiction king has a call number on its spine\", 'king', 2),\n",
    "    }\n",
    "    \n",
    "    this_raw_sentence, this_word, this_pos = tests[which_test]\n",
    "    this_mod, this_tok, this_pref = module_dict[model_name]()\n",
    "    \n",
    "    this_sentence = model_score_utils.prepSentence(this_raw_sentence)\n",
    "\n",
    "    # Below: target \"book\" as the sanity check.\n",
    "    position = sub_analysis.find_true_token_position(this_sentence, this_word, this_pos, this_tok)\n",
    "\n",
    "    # Note: above position is NOT with CLS added. This is accounted for in process_single_substitution. \n",
    "\n",
    "    if position == -2: return None\n",
    "    # The desired token was probably fragmented by the tokenizer.\n",
    "    # That is, the changed word couldn't be found in whole form after tokenization.\n",
    "\n",
    "    position = position + 1\n",
    "    # This is because CLS is not accounted for in the original index. This is for correctness of the prefixes.\n",
    "\n",
    "    this_token_prefix, orig_tokens = this_pref(this_sentence, this_tok, [position])\n",
    "\n",
    "    this_ground_truth_idx = orig_tokens[position]\n",
    "\n",
    "    logit_position = position if not isinstance(this_mod, GPT2LMHeadModel) else position - 1\n",
    "    # GPT-2 stores the prediction for word i+1 at word i, so need to decrease the prediction position by 1.\n",
    "\n",
    "    ground_truth_probs, all_probs, all_pos_all_probs = model_score_utils.get_model_probabilities(this_token_prefix, this_mod, this_ground_truth_idx, logit_position, verifying = True)\n",
    "\n",
    "    #check_df = report_mask_words(all_probs, this_sentence, this_tok)\n",
    "    \n",
    "    print('This ground truth probability', ground_truth_probs)\n",
    "\n",
    "    #for pos_idx, pos_arr in enumerate(all_pos_all_probs.squeeze()):\n",
    "    #    print(pos_idx)\n",
    "    #    print(pos_arr.shape)\n",
    "    #    print(report_mask_words(pos_arr, this_sentence, this_tok))\n",
    "        \n",
    "    return None\n",
    "    #return check_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test name: book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ground truth probability 0.0062323459424078465\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-08f74bc4a8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'For test name: {test_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#['book', 'go']: # This line is used for BERT testing specifically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mthis_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_softmax_extraction_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(f' ************** For model: {this_name}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(this_check)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-96aadf9efd18>\u001b[0m in \u001b[0;36mtest_softmax_extraction_indexing\u001b[0;34m(model_name, which_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#    print(report_mask_words(pos_arr, this_sentence, this_tok))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'check_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# The contrast between \"book\" and \"go\" here might be an example of left-to-right context being advantageous?\n",
    "for this_name in ['bert']:\n",
    "    for test_name in ['book', 'king']: # high surprisal sanity check\n",
    "        print(f'For test name: {test_name}')\n",
    "        #['book', 'go']: # This line is used for BERT testing specifically.\n",
    "        this_check = test_softmax_extraction_indexing(this_name, test_name)\n",
    "        #print(f' ************** For model: {this_name}')\n",
    "        #print(this_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', 'Ġ.']\n",
      "Reporting most likely tokens to complete 'Each nonfiction book has a call number on its spine .' in descending order\n",
      " ************** For model: gpt2_normal\n",
      "            Word  Score value\n",
      "0          Ġbook      0.43874\n",
      "1    Ġcollection      0.03458\n",
      "2        Ġauthor      0.03377\n",
      "3         Ġnovel      0.03154\n",
      "4        Ġwriter      0.02460\n",
      "5   Ġpublication      0.02202\n",
      "6              ,      0.01822\n",
      "7       Ġproject      0.01615\n",
      "8         Ġstory      0.01560\n",
      "9            Ġor      0.01478\n",
      "10        Ġpiece      0.01282\n",
      "11      Ġarticle      0.00980\n",
      "12      Ġjournal      0.00950\n",
      "13       Ġseries      0.00910\n",
      "14          Ġand      0.00872\n",
      "15         Ġwork      0.00862\n",
      "16             /      0.00654\n",
      "17    Ġanthology      0.00631\n",
      "18       Ġvolume      0.00626\n",
      "19        Ġissue      0.00611\n",
      "['Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', 'Ġ.']\n",
      "Reporting most likely tokens to complete 'Each nonfiction book has a call number on its spine .' in descending order\n",
      " ************** For model: gpt2_medium\n",
      "            Word  Score value\n",
      "0          Ġbook      0.43874\n",
      "1    Ġcollection      0.03458\n",
      "2        Ġauthor      0.03377\n",
      "3         Ġnovel      0.03154\n",
      "4        Ġwriter      0.02460\n",
      "5   Ġpublication      0.02202\n",
      "6              ,      0.01822\n",
      "7       Ġproject      0.01615\n",
      "8         Ġstory      0.01560\n",
      "9            Ġor      0.01478\n",
      "10        Ġpiece      0.01282\n",
      "11      Ġarticle      0.00980\n",
      "12      Ġjournal      0.00950\n",
      "13       Ġseries      0.00910\n",
      "14          Ġand      0.00872\n",
      "15         Ġwork      0.00862\n",
      "16             /      0.00654\n",
      "17    Ġanthology      0.00631\n",
      "18       Ġvolume      0.00626\n",
      "19        Ġissue      0.00611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '.']\n",
      "Reporting most likely tokens to complete 'Each nonfiction book has a call number on its spine .' in descending order\n",
      " ************** For model: bert\n",
      "         Word  Score value\n",
      "0        card      0.16120\n",
      "1       phone      0.15131\n",
      "2   telephone      0.14339\n",
      "3         box      0.06001\n",
      "4     ##phone      0.04606\n",
      "5       ##box      0.02496\n",
      "6     ##board      0.02247\n",
      "7        ##et      0.01850\n",
      "8       ##pad      0.01204\n",
      "9      ##book      0.01180\n",
      "10        set      0.01168\n",
      "11       unit      0.00985\n",
      "12   receiver      0.00928\n",
      "13       also      0.00890\n",
      "14    machine      0.00853\n",
      "15     button      0.00709\n",
      "16       book      0.00623\n",
      "17        ##r      0.00623\n",
      "18       ##er      0.00608\n",
      "19       case      0.00584\n",
      "['Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', 'Ġ.']\n",
      "Reporting most likely tokens to complete 'Each nonfiction book has a call number on its spine .' in descending order\n",
      " ************** For model: bart\n",
      "            Word  Score value\n",
      "0          Ġbook      0.59303\n",
      "1         Ġnovel      0.04337\n",
      "2    Ġmanuscript      0.01909\n",
      "3         Ġtitle      0.01876\n",
      "4         Ġstory      0.01732\n",
      "5        Ġvolume      0.01681\n",
      "6         Ġpiece      0.01571\n",
      "7    Ġcollection      0.01407\n",
      "8   Ġpublication      0.01175\n",
      "9          Ġwork      0.01093\n",
      "10     Ġmagazine      0.00876\n",
      "11       Ġwriter      0.00787\n",
      "12         Ġfilm      0.00692\n",
      "13      Ġchapter      0.00646\n",
      "14           Ġor      0.00638\n",
      "15      Ġfiction      0.00620\n",
      "16      Ġarticle      0.00586\n",
      "17    Ġpublished      0.00508\n",
      "18       Ġauthor      0.00447\n",
      "19       Ġseries      0.00420\n"
     ]
    }
   ],
   "source": [
    "for this_name in ['gpt2_normal', 'gpt2_medium', 'bert', 'bart']:\n",
    "    this_check = test_softmax_extraction_indexing(this_name, 'book')\n",
    "    print(f' ************** For model: {this_name}')\n",
    "    print(this_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for correctness of position of extraction/the softmax extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will compare the user transcription scored softmax against the ones produced by the new code from predicting from editTables\n",
    "\n",
    "\n",
    "Since the model score utils function was generally checked for correctness\n",
    "\n",
    "will just check the user transcription, since the arguments/function for response are parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_runs_idx_from_sub_idx(case_sentence):\n",
    "    return list(all_runs['user_candidate_transcription']).index(case_sentence)\n",
    "\n",
    "def report(case_idx, df_entry, this_word, raw_prob, new_prob):\n",
    "    this_report = f\"Mismatch in probabilities for entry {case_idx}.\"\n",
    "    this_report += f\"\\n\\t Word change original prob: {new_prob}\"\n",
    "    this_report += f\"\\n\\t List of probs from precomputed, prob entry: {raw_prob}\"\n",
    "    this_report += f\"\\n\\t Word of interest: {this_word}\"\n",
    "    this_report += f\"\\n\\t{df_entry}\"\n",
    "    return this_report\n",
    "    \n",
    "def compare_probs_model_case_idx(case_idx, model_name, this_model, this_tokenizer, this_prefix_func):\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks each of the sentences in all_runs to see\n",
    "    if the newly computed probabilities and the old ones from new_model_runs.py\n",
    "    match, as a sanity check\n",
    "    \"\"\"\n",
    "\n",
    "    df = all_changes_probs[model_name]\n",
    "    \n",
    "    this_df_entry = df.iloc[case_idx]\n",
    "    sentence_idx = get_all_runs_idx_from_sub_idx(this_df_entry['sentence'])\n",
    "    # Above: use the unprepped version to index correctly into all_runs.csv\n",
    "    \n",
    "    case_sentence = model_score_utils.prepSentence(this_df_entry['sentence'])\n",
    "    \n",
    "    # Above: It's important that prepSentence is used on all sentence calculations.\n",
    "    # For example, in case_idx = 245, not using prepSentence will result in lowercase \"failure\", which tokenizes as \"fail/ure\"\n",
    "    # However, prepSentence will make failure \"Failure\", which will not break in tokenization.\n",
    "    # This will change which word index you extract from as the \"true index\".\n",
    "\n",
    "    # Get the word change csv probability for this word\n",
    "    word_change_orig_prob = this_df_entry['orig_prob']\n",
    "\n",
    "    # Get the precomputed probability for this word from the raw \"run model save\" DataFrames\n",
    "    # in the long running computation\n",
    "\n",
    "    # This is to index into the right df from above\n",
    "    # 5/31 Indexing: https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-in-a-list\n",
    "    \n",
    "    orig_scores = raw_probs[model_name if model_name != 'gpt2' else model_name + '_normal'][sentence_idx]\n",
    "\n",
    "    # This is to change the sCounter to account for broken word tokenization in the original dataframes\n",
    "    # Specifically, relocated_idx is the final index position of the target word\n",
    "    # in the original raw probability DFs.\n",
    "    #      There is no need to adjust this index for CLS, etc. because CLS is not present in the dataframe\n",
    "    #      And the index is found using the dataframe directly.\n",
    "    relocated_idx = sub_analysis.find_true_token_position(case_sentence, this_df_entry['sWord'], int(this_df_entry['sCounter']), this_tokenizer)\n",
    "\n",
    "    # If the sWord was tokenizer-broken then it should mark it as such in the new dataframe\n",
    "    if relocated_idx == -2: \n",
    "        # Below assert checks to make sure that the target word really isn't in the tokenized list\n",
    "        assert not this_df_entry['sWord'] in orig_scores['word'], '{}, {}'.format(orig_scores['word'], this_df_entry['sWord'])\n",
    "        \n",
    "        word_change_has_nan = pd.isnull(word_change_orig_prob)\n",
    "        assert word_change_has_nan, 'Did not mark broken word as NaN probability'\n",
    "        \n",
    "        return None\n",
    "\n",
    "    this_word = this_df_entry['sWord']\n",
    "\n",
    "    \n",
    "    prior_prob_calculation_df = orig_scores.iloc[relocated_idx]\n",
    "\n",
    "    raw_orig_prob = prior_prob_calculation_df['prob']\n",
    "\n",
    "    # Compare the two computations to each other.\n",
    "    if abs(word_change_orig_prob - raw_orig_prob) > 1e-6:\n",
    "        print(report(case_idx, this_df_entry, this_word, raw_orig_prob, word_change_orig_prob))\n",
    "        print('***** RELOCATED IDX **** ', relocated_idx)\n",
    "        print(orig_scores)\n",
    "        mismatches[model_name].append((case_idx, this_word, word_change_orig_prob, orig_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each nonfiction book has a call number on its spine\n",
      "token prefixes ['<|endoftext|>', 'Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "From the new dfs 0.043548859655857086\n",
      "From the old dfs        word      prob\n",
      "0      Each  0.000269\n",
      "1      Ġnon  0.000262\n",
      "2   fiction  0.011790\n",
      "3     Ġbook  0.438744\n",
      "4      Ġhas  0.057975\n",
      "5        Ġa  0.289296\n",
      "6     Ġcall  0.000068\n",
      "7   Ġnumber  0.000363\n",
      "8       Ġon  0.043549\n",
      "9      Ġits  0.095197\n",
      "10   Ġspine  0.051601\n"
     ]
    }
   ],
   "source": [
    "def run_sub_analysis_idx(case_idx, model_name):\n",
    "    \"\"\"\n",
    "    Useful for running the function directly for print statements\n",
    "    \"\"\"\n",
    "    \n",
    "    df = all_changes_probs[model_name].iloc[case_idx]\n",
    "    raw_sentence = df['sentence']\n",
    "    word = df['sWord']\n",
    "    position = df['sCounter']\n",
    "    model, tokenizer, prefix_func = module_dict[model_name]()\n",
    "    \n",
    "    result = sub_analysis.process_single_substitution(raw_sentence, word, position, model, tokenizer, prefix_func, verifying = False)\n",
    "    return result\n",
    "\n",
    "shift_index = 246\n",
    "norm_index = 0\n",
    "\n",
    "#this_case_index = shift_index\n",
    "this_case_index = norm_index\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "#compare_probs_model_case_idx(246, 'gpt2_normal')\n",
    "tdf = all_changes_probs['gpt2_normal'].iloc[this_case_index]\n",
    "this_sentence = tdf['sentence']\n",
    "print(this_sentence)\n",
    "result = run_sub_analysis_idx(this_case_index, 'gpt2_normal')\n",
    "\n",
    "print('From the new dfs', result)\n",
    "print('From the old dfs', raw_probs['gpt2_normal'][get_all_runs_idx_from_sub_idx(this_sentence)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING NEW MODEL SET: gpt2_normal\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n",
      "BEGINNING NEW MODEL SET: gpt2_medium\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING NEW MODEL SET: bert\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n",
      "BEGINNING NEW MODEL SET: bart\n",
      "Current case idx: 0 / 1366\n",
      "Current case idx: 100 / 1366\n",
      "Current case idx: 200 / 1366\n",
      "Current case idx: 300 / 1366\n",
      "Current case idx: 400 / 1366\n",
      "Current case idx: 500 / 1366\n",
      "Current case idx: 600 / 1366\n",
      "Current case idx: 700 / 1366\n",
      "Current case idx: 800 / 1366\n",
      "Current case idx: 900 / 1366\n",
      "Current case idx: 1000 / 1366\n",
      "Current case idx: 1100 / 1366\n",
      "Current case idx: 1200 / 1366\n",
      "Current case idx: 1300 / 1366\n"
     ]
    }
   ],
   "source": [
    "# Check all of the positions and model names\n",
    "\n",
    "mismatches = defaultdict(list)\n",
    "\n",
    "for model_name in all_changes_probs:\n",
    "    \n",
    "    this_model, this_tokenizer, this_prefix_func = module_dict[model_name]()\n",
    "    print(f'BEGINNING NEW MODEL SET: {model_name}')\n",
    "\n",
    "    for case_idx in range(len(df)):\n",
    "        \n",
    "        if case_idx % 100 == 0: print(f'Current case idx: {case_idx} / {len(df)}')\n",
    "            \n",
    "        compare_probs_model_case_idx(case_idx, model_name, this_model, this_tokenizer, this_prefix_func)\n",
    "        \n",
    "assert not mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix completion check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "The probability of this completion is: 0.0008465127320960164\n"
     ]
    }
   ],
   "source": [
    "# GPT-2 prefix completion check\n",
    "# Directly passing in a prefix to the single substitution method.\n",
    "\n",
    "# Shows that GPT-2 is not good at predicting \"on\"\n",
    "#  despite reasonable results on \"It's time to go the\" case\n",
    "#  and also predicting \"Each nonfiction book has a call number on its\"\n",
    "\n",
    "importlib.reload(sub_analysis)\n",
    "importlib.reload(model_score_utils)\n",
    "\n",
    "this_df = all_changes_probs['gpt2_normal'].iloc[0]\n",
    "model, tok, prefix_func = model_score_funcs.get_gpt2_modules()\n",
    "\n",
    "# Applying prepSentence to manually specified prefix will artifically end the phrase with a period,\n",
    "# that is, within this test,\n",
    "# which is not the same as the actual code's behavior.\n",
    "\n",
    "#test_sentence = f\"it's time to go to the \"\n",
    "test_sentence = f'{tok.bos_token}Each nonfiction book has a call number'\n",
    "\n",
    "this_tokens = tok.encode(test_sentence)\n",
    "\n",
    "print(tok.convert_ids_to_tokens(this_tokens))\n",
    "this_pred_pos = len(this_tokens) - 1\n",
    "\n",
    "# The 0 is a filler index.\n",
    "prob_at_ground_truth, probs, _ = model_score_utils.get_model_probabilities(this_tokens, model, 0, this_pred_pos, verifying = True)\n",
    "#result_df = report_mask_words(probs, test_sentence, tok)\n",
    "#print(result_df)\n",
    "\n",
    "print(f'The probability of this completion is: {prob_at_ground_truth}')\n",
    "\n",
    "# It seems to be an inability to tolerate the sentence itself -- why?\n",
    "# Despite it working on the \"it's time to go to the\" case\n",
    "\n",
    "# Printout from real model inference code (running it with process_single_substitution): the translated tokens are:\n",
    "# ['<|endoftext|>', 'Each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber'] \n",
    "\n",
    "# What was done to fix this test so that the probabilities match in the saved and non-saved version:\n",
    "# Basically minor changes in the prefix have impact on how probabilities match\n",
    "\n",
    "# The first is not to apply prepSentence to a manually specified incomplete prefix, otherwise it will artifically add a period to the end\n",
    "# Don't add a space between bos_token and the beginning of the sentence, or it will mark the first word of the sentence with an extra whitespace symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the true token position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for correctness of substitution processing\n",
    "\n",
    "WORD_CHANGES_FOLDER = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/word_changes'\n",
    "\n",
    "substitution_df = pd.read_csv(join(WORD_CHANGES_FOLDER, 'edit_substitutions.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_true_token_pos_both(df_entry, model, tokenizer, prefix_func):\n",
    "    \n",
    "    # Need to check if these are 0 indexed?\n",
    "    \n",
    "    orig_loc = sub_analysis.find_true_token_position(df_entry['sentence'], df_entry['sWord'], int(df_entry['sCounter']), tokenizer)\n",
    "    edited_loc = sub_analysis.find_true_token_position(df_entry['response'], df_entry['rWord'], int(df_entry['rCounter']), tokenizer)\n",
    "    \n",
    "    return orig_loc, edited_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-aeca8740385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Handle cannot find case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_true_token_pos_both\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_score_funcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bert_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/model_score_funcs.py\u001b[0m in \u001b[0;36mget_bert_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#2/20: https://albertauyeung.github.io/2020/06/19/bert-tokenization.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased-whole-word-masking'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             )\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# Prune heads if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m_init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;31m# Slightly different from the TF version which uses truncated_normal for initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;31m# cf https://github.com/pytorch/pytorch/pull/5617\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# GPT-2 tests for find\n",
    "\n",
    "# Handle unchanged and changed case, GPT-2\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_gpt2_modules())\n",
    "assert result == (8,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_gpt2_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n",
    "\n",
    "\n",
    "# BERT tests for find\n",
    "\n",
    "# Handle unchanged and changed case, BERT\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_bert_modules())\n",
    "assert result == (7,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_bert_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n",
    "\n",
    "\n",
    "\n",
    "# BART tests for find\n",
    "\n",
    "# Handle unchanged and changed case, BART\n",
    "result = find_true_token_pos_both(substitution_df.iloc[0], *model_score_funcs.get_bart_modules())\n",
    "assert result == (8,8)\n",
    "\n",
    "# Handle cannot find case\n",
    "result = find_true_token_pos_both(substitution_df.iloc[8], *model_score_funcs.get_bart_modules())\n",
    "assert result == (-2,1) # The first one is \"dietitian\", which is broken up. The second is \"priest\", which is normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>code</th>\n",
       "      <th>sWord</th>\n",
       "      <th>rWord</th>\n",
       "      <th>sCounter</th>\n",
       "      <th>rCounter</th>\n",
       "      <th>sentence</th>\n",
       "      <th>response</th>\n",
       "      <th>sLeftSequence</th>\n",
       "      <th>rLeftSequence</th>\n",
       "      <th>sRightSequence</th>\n",
       "      <th>rRightSequence</th>\n",
       "      <th>input_subject</th>\n",
       "      <th>output_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>on</td>\n",
       "      <td>in</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>each nonfiction book has a call number on its ...</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>call number on</td>\n",
       "      <td>call number in</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>has</td>\n",
       "      <td>had</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>fiction book has</td>\n",
       "      <td>nonfiction book had</td>\n",
       "      <td>has a call</td>\n",
       "      <td>had a call</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>S</td>\n",
       "      <td>in</td>\n",
       "      <td>on</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>call number in</td>\n",
       "      <td>call number on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>12</td>\n",
       "      <td>twelve</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>each non fiction book had 12 numbers on its spine</td>\n",
       "      <td>each nonfiction book had twelve numbers on its...</td>\n",
       "      <td>book had 12</td>\n",
       "      <td>book had twelve</td>\n",
       "      <td>12 numbers on</td>\n",
       "      <td>twelve numbers on</td>\n",
       "      <td>dc02e8bc38234eed94e4e0cfbe083801</td>\n",
       "      <td>e1f5fb8bc21048cb8a50771b80eda39a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>numbers</td>\n",
       "      <td>notches</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>each non fiction book had twelve numbers on it...</td>\n",
       "      <td>each nonfiction book had twelve notches on its...</td>\n",
       "      <td>had twelve numbers</td>\n",
       "      <td>had twelve notches</td>\n",
       "      <td>numbers on its</td>\n",
       "      <td>notches on its</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>a575811edc0841b082724370f678d574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 code    sWord    rWord  sCounter  rCounter  \\\n",
       "0          11    S       on       in       7.0       8.0   \n",
       "1          11    S      has      had       4.0       3.0   \n",
       "2          12    S       in       on       8.0       7.0   \n",
       "3          13    S       12   twelve       5.0       4.0   \n",
       "4          13    S  numbers  notches       6.0       5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  each nonfiction book has a call number on its ...   \n",
       "1  each non fiction book has a call number in its...   \n",
       "2  each non fiction book has a call number in its...   \n",
       "3  each non fiction book had 12 numbers on its spine   \n",
       "4  each non fiction book had twelve numbers on it...   \n",
       "\n",
       "                                            response       sLeftSequence  \\\n",
       "0  each non fiction book has a call number in its...      call number on   \n",
       "1  each nonfiction book had a call number on its ...    fiction book has   \n",
       "2  each nonfiction book had a call number on its ...      call number in   \n",
       "3  each nonfiction book had twelve numbers on its...         book had 12   \n",
       "4  each nonfiction book had twelve notches on its...  had twelve numbers   \n",
       "\n",
       "         rLeftSequence  sRightSequence     rRightSequence  \\\n",
       "0       call number in    on its spine                NaN   \n",
       "1  nonfiction book had      has a call         had a call   \n",
       "2       call number on             NaN       on its spine   \n",
       "3      book had twelve   12 numbers on  twelve numbers on   \n",
       "4   had twelve notches  numbers on its     notches on its   \n",
       "\n",
       "                      input_subject                    output_subject  \n",
       "0                                 0  8cf6535ea0ae4addb28f5f90a2b13a7d  \n",
       "1  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc  \n",
       "2  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc  \n",
       "3  dc02e8bc38234eed94e4e0cfbe083801  e1f5fb8bc21048cb8a50771b80eda39a  \n",
       "4  53edaed0aee2422e96af6c0d3d636962  a575811edc0841b082724370f678d574  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 1\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', '[MASK]', 'a', 'call', 'number', 'in', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', '[MASK]', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 2\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 3\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'had', '[MASK]', 'numbers', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', '[MASK]', 'numbers', 'on', 'its', 'spine', '[SEP]']\n",
      "\n",
      "Entry 4\n",
      "['[CLS]', 'each', 'non', 'fiction', 'book', 'had', 'twelve', '[MASK]', 'on', 'its', 'spine', '[SEP]']\n",
      "Fragmented\n",
      "\n",
      "\n",
      "\n",
      "Entry 0\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "\n",
      "Entry 1\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook']\n",
      "\n",
      "Entry 2\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "\n",
      "Entry 3\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad']\n",
      "\n",
      "Entry 4\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', 'Ġtwelve']\n",
      "Fragmented\n",
      "\n",
      "\n",
      "\n",
      "Entry 0\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 1\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', '<mask>', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġin', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', '<mask>', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 2\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhas', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 3\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', '<mask>', 'Ġnumbers', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', '<mask>', 'Ġnumbers', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "\n",
      "Entry 4\n",
      "['<s>', 'each', 'Ġnon', 'Ġfiction', 'Ġbook', 'Ġhad', 'Ġtwelve', '<mask>', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "Fragmented\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking prefix correctness with the true position finding\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_bert_modules())\n",
    "\n",
    "print(); print()\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_gpt2_modules())\n",
    "\n",
    "print(); print()\n",
    "\n",
    "result = sub_analysis.analyze_substitutions(substitution_df.head(), *model_score_funcs.get_bart_modules())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking expected saving behavior for the single_substitution predictions and the edit saves.\n",
    "# Results saved on the prefix. These are just for debugging purposes.\n",
    "\n",
    "debug_save_results_folder = '/home/nwong/chompsky/serial_chain/telephone-analysis-public/intermediate_results/word_changes_prefix_only'\n",
    "debug_save_results_path = join(debug_save_results_folder, 'word_change_probs.csv')\n",
    "\n",
    "results_df = pd.read_csv(debug_save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>code</th>\n",
       "      <th>sWord</th>\n",
       "      <th>rWord</th>\n",
       "      <th>sCounter</th>\n",
       "      <th>rCounter</th>\n",
       "      <th>sentence</th>\n",
       "      <th>response</th>\n",
       "      <th>sLeftSequence</th>\n",
       "      <th>rLeftSequence</th>\n",
       "      <th>sRightSequence</th>\n",
       "      <th>rRightSequence</th>\n",
       "      <th>input_subject</th>\n",
       "      <th>output_subject</th>\n",
       "      <th>orig_prob</th>\n",
       "      <th>edited_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>on</td>\n",
       "      <td>in</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>each nonfiction book has a call number on its ...</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>call number on</td>\n",
       "      <td>call number in</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>0.350487</td>\n",
       "      <td>0.057322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>has</td>\n",
       "      <td>had</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>fiction book has</td>\n",
       "      <td>nonfiction book had</td>\n",
       "      <td>has a call</td>\n",
       "      <td>had a call</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "      <td>0.338602</td>\n",
       "      <td>0.007203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>S</td>\n",
       "      <td>in</td>\n",
       "      <td>on</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>each non fiction book has a call number in its...</td>\n",
       "      <td>each nonfiction book had a call number on its ...</td>\n",
       "      <td>call number in</td>\n",
       "      <td>call number on</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on its spine</td>\n",
       "      <td>8cf6535ea0ae4addb28f5f90a2b13a7d</td>\n",
       "      <td>edf8f705ab7241a191fa3ae24e381ebc</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.355695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>12</td>\n",
       "      <td>twelve</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>each non fiction book had 12 numbers on its spine</td>\n",
       "      <td>each nonfiction book had twelve numbers on its...</td>\n",
       "      <td>book had 12</td>\n",
       "      <td>book had twelve</td>\n",
       "      <td>12 numbers on</td>\n",
       "      <td>twelve numbers on</td>\n",
       "      <td>dc02e8bc38234eed94e4e0cfbe083801</td>\n",
       "      <td>e1f5fb8bc21048cb8a50771b80eda39a</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>numbers</td>\n",
       "      <td>notches</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>each non fiction book had twelve numbers on it...</td>\n",
       "      <td>each nonfiction book had twelve notches on its...</td>\n",
       "      <td>had twelve numbers</td>\n",
       "      <td>had twelve notches</td>\n",
       "      <td>numbers on its</td>\n",
       "      <td>notches on its</td>\n",
       "      <td>53edaed0aee2422e96af6c0d3d636962</td>\n",
       "      <td>a575811edc0841b082724370f678d574</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1 code    sWord    rWord  sCounter  rCounter  \\\n",
       "0           0            11    S       on       in       7.0       8.0   \n",
       "1           1            11    S      has      had       4.0       3.0   \n",
       "2           2            12    S       in       on       8.0       7.0   \n",
       "3           3            13    S       12   twelve       5.0       4.0   \n",
       "4           4            13    S  numbers  notches       6.0       5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  each nonfiction book has a call number on its ...   \n",
       "1  each non fiction book has a call number in its...   \n",
       "2  each non fiction book has a call number in its...   \n",
       "3  each non fiction book had 12 numbers on its spine   \n",
       "4  each non fiction book had twelve numbers on it...   \n",
       "\n",
       "                                            response       sLeftSequence  \\\n",
       "0  each non fiction book has a call number in its...      call number on   \n",
       "1  each nonfiction book had a call number on its ...    fiction book has   \n",
       "2  each nonfiction book had a call number on its ...      call number in   \n",
       "3  each nonfiction book had twelve numbers on its...         book had 12   \n",
       "4  each nonfiction book had twelve notches on its...  had twelve numbers   \n",
       "\n",
       "         rLeftSequence  sRightSequence     rRightSequence  \\\n",
       "0       call number in    on its spine                NaN   \n",
       "1  nonfiction book had      has a call         had a call   \n",
       "2       call number on             NaN       on its spine   \n",
       "3      book had twelve   12 numbers on  twelve numbers on   \n",
       "4   had twelve notches  numbers on its     notches on its   \n",
       "\n",
       "                      input_subject                    output_subject  \\\n",
       "0                                 0  8cf6535ea0ae4addb28f5f90a2b13a7d   \n",
       "1  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc   \n",
       "2  8cf6535ea0ae4addb28f5f90a2b13a7d  edf8f705ab7241a191fa3ae24e381ebc   \n",
       "3  dc02e8bc38234eed94e4e0cfbe083801  e1f5fb8bc21048cb8a50771b80eda39a   \n",
       "4  53edaed0aee2422e96af6c0d3d636962  a575811edc0841b082724370f678d574   \n",
       "\n",
       "   orig_prob  edited_prob  \n",
       "0   0.350487     0.057322  \n",
       "1   0.338602     0.007203  \n",
       "2   0.057322     0.355695  \n",
       "3   0.002778     0.000954  \n",
       "4   0.005896          NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick dataset analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many sentences were affected by tokenization misalignments.\n",
    "# This will load the aligned versions of the results, where the broken words were taken out\n",
    "\n",
    "\n",
    "DATA_PREP_FOLDER = './intermediate_results/data_prep_logistic'\n",
    "lm = load_runs.load_logistic_prep(DATA_PREP_FOLDER)\n",
    "\n",
    "\n",
    "model_key = 'gpt2_normal'\n",
    "\n",
    "# Need to compare words. Should be enough to compare length of the two as a first pass.\n",
    "\n",
    "all_count = 0\n",
    "\n",
    "for model in transformer_names:\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    aligned_score_list = lm[model+'_scores']\n",
    "    raw_score_list = raw_scores[model]\n",
    "    assert len(aligned_score_list) == len(raw_score_list)\n",
    "    \n",
    "    \n",
    "    for i in range(len(aligned_score_list)):\n",
    "        if len(aligned_score_list[i]) != len(raw_score_list[i]):\n",
    "            count += 1\n",
    "    print(f'Model: {model}, Number of alignment length difference: {count} / {len(aligned_score_list)}')\n",
    "    all_count += count\n",
    "\n",
    "print(f'Total misalignment over all models: {all_count}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the editTables word substitution yield is kind of low:\n",
    "\n",
    "22482 entries were matches\n",
    "\n",
    "3135 entries were insertions\n",
    "\n",
    "3442 entries were deletions\n",
    "\n",
    "1366 entries were substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_by_one_sub = []\n",
    "\n",
    "def check_single_change(entry):\n",
    "    sent = entry['sentence'].split()\n",
    "    resp = entry['response'].split()\n",
    "    \n",
    "    filler_text = '<FILLER>'\n",
    "    sent[int(entry['sCounter'])] = filler_text\n",
    "    resp[int(entry['rCounter'])] = filler_text\n",
    "    \n",
    "    return sent == resp # Then?\n",
    "\n",
    "\n",
    "def test_check_single_change():\n",
    "    neg_case = check_single_change(substitution_df.iloc[0])\n",
    "    pos_case = check_single_change(substitution_df.iloc[12])\n",
    "\n",
    "    print(f'Neg case: {neg_case}')\n",
    "    print(f'Pos case: {pos_case}') # This works. Now run this on everything\n",
    "\n",
    "    \n",
    "# Run on the entire dataframe?\n",
    "\n",
    "ok_sentences = []\n",
    "for i in range(len(substitution_df)):\n",
    "    if check_single_change(substitution_df.iloc[i]):\n",
    "        ok_sentences.append(i)\n",
    "        \n",
    "print(f'Number of single substitution sentences: {len(ok_sentences)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telephone-env-3",
   "language": "python",
   "name": "telephone-env-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
