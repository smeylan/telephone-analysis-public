{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertForMaskedLM, BertTokenizer, BartForConditionalGeneration, BartTokenizer\n",
    "from new_models import model_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = {\n",
    "    'gpt2': GPT2LMHeadModel.from_pretrained('gpt2'),\n",
    "    'bert': BertForMaskedLM.from_pretrained('bert-large-uncased-whole-word-masking'),\n",
    "    'bart': BartForConditionalGeneration.from_pretrained('facebook/bart-base'),\n",
    "    \n",
    "}\n",
    "\n",
    "tokenizers = {\n",
    "    'gpt2': GPT2Tokenizer.from_pretrained('gpt2'),\n",
    "    'bert': BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\"),\n",
    "    'bart': BartTokenizer.from_pretrained(\"facebook/bart-base\"),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other scratchwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2_normal\n",
      "For model: gpt2_normal, length: 3193\n",
      "gpt2_medium\n",
      "For model: gpt2_medium, length: 3193\n",
      "bert\n",
      "For model: bert, length: 3193\n",
      "bart\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-401-aaa8d5eddb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gpt2_normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gpt2_medium'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtemp_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRESULTS_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#sentence_score = prep_probs.load_sentence_scores(model_name, RESULTS_FOLDER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'For model: {model_name}, length: {len(temp_results[model_name])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/prep_probs.py\u001b[0m in \u001b[0;36mload_word_scores\u001b[0;34m(model_name, results_folder)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Always omit EOS from the calculations, for both word and sentence scoring.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mfiltered_raw_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_eos_punct_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mneg_surprisals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#for idx, this_process_df in enumerate(filtered_raw_scores):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/prep_probs.py\u001b[0m in \u001b[0;36mprobability_to_negative_surprisal\u001b[0;34m(this_df)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthis_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_word_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3450\u001b[0m         \u001b[0;31m# value exception to occur first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3452\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   3243\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3245\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Looking at test saves for the model scores\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "\n",
    "from new_models import prep_probs\n",
    "\n",
    "RESULTS_FOLDER = './intermediate_results/new_models_probs'\n",
    "\n",
    "temp_results = {}\n",
    "for model_name in ['gpt2_normal', 'gpt2_medium', 'bert', 'bart']:\n",
    "    print(model_name)\n",
    "    temp_results[model_name] = prep_probs.load_word_scores(model_name, RESULTS_FOLDER)\n",
    "    print(f'For model: {model_name}, length: {len(temp_results[model_name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word      prob\n",
      "0      Each  0.051310\n",
      "1      Ġnon  0.708738\n",
      "2   fiction  0.336515\n",
      "3     Ġbook  0.593027\n",
      "4      Ġhas  0.152824\n",
      "5        Ġa  0.731974\n",
      "6     Ġcall  0.000202\n",
      "7   Ġnumber  0.000671\n",
      "8       Ġon  0.287921\n",
      "9      Ġits  0.252410\n",
      "10   Ġspine  0.007092\n"
     ]
    }
   ],
   "source": [
    "temp_results['bart'] = prep_probs.load_word_scores('bart', RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2\n",
      "Processing model name: gpt2_normal\n",
      "       word      prob\n",
      "0      Each  0.000269\n",
      "1      Ġnon  0.000262\n",
      "2   fiction  0.011790\n",
      "3     Ġbook  0.438744\n",
      "4      Ġhas  0.057975\n",
      "5        Ġa  0.289296\n",
      "6     Ġcall  0.000068\n",
      "7   Ġnumber  0.000363\n",
      "8       Ġon  0.043549\n",
      "9      Ġits  0.095197\n",
      "10   Ġspine  0.051601\n",
      "Index: 0\n",
      "gpt2\n",
      "Processing model name: gpt2_medium\n",
      "       word      prob\n",
      "0      Each  0.000595\n",
      "1      Ġnon  0.000134\n",
      "2   fiction  0.011834\n",
      "3     Ġbook  0.683527\n",
      "4      Ġhas  0.055999\n",
      "5        Ġa  0.325504\n",
      "6     Ġcall  0.000187\n",
      "7   Ġnumber  0.002454\n",
      "8       Ġon  0.087685\n",
      "9      Ġits  0.168300\n",
      "10   Ġspine  0.049400\n",
      "Index: 0\n",
      "bert\n",
      "Processing model name: bert\n",
      "         word      prob\n",
      "0        each  0.472037\n",
      "1  nonfiction  0.000103\n",
      "2        book  0.006232\n",
      "3         has  0.809371\n",
      "4           a  0.942987\n",
      "5        call  0.002517\n",
      "6      number  0.024608\n",
      "7          on  0.937234\n",
      "8         its  0.387401\n",
      "9       spine  0.009837\n",
      "Index: 0\n"
     ]
    }
   ],
   "source": [
    "import align_prep_words\n",
    "importlib.reload(align_prep_words)\n",
    "\n",
    "importlib.reload(prep_probs)\n",
    "\n",
    "word_list = [df['word'].values.tolist() for df in lm['bnc_unigram']]\n",
    "\n",
    "transformer_names = ['gpt2_normal', 'gpt2_medium', 'bert']#, 'bart']\n",
    "tokenizer_names = ['gpt2', 'gpt2', 'bert']#, 'bart']\n",
    "\n",
    "sel_idx = 20\n",
    "for model_name, tokenizer_name in zip(transformer_names, tokenizer_names):\n",
    "\n",
    "    print(tokenizer_name)\n",
    "    print(f'Processing model name: {model_name}')\n",
    "    \n",
    "    raw_scores = prep_probs.load_word_scores(model_name, RESULTS_FOLDER)\n",
    "    lm[f'{model_name}_scores'] = align_prep_words.align_model_word_dfs(raw_scores[:sel_idx],\n",
    "                                                                       tokenizers[tokenizer_name],\n",
    "                                                                       word_list[:sel_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       prob        word\n",
      "0 -3.570354        each\n",
      "1       NaN  nonfiction\n",
      "2 -0.357789        book\n",
      "3 -1.236761         has\n",
      "4 -0.538658           a\n",
      "5 -4.164424        call\n",
      "6 -3.439832      number\n",
      "7 -1.361023          on\n",
      "8 -1.021375         its\n",
      "9 -1.287340       spine\n",
      "       word      prob\n",
      "0      Each -3.570354\n",
      "1      Ġnon -3.581758\n",
      "2   fiction -1.928502\n",
      "3     Ġbook -0.357789\n",
      "4      Ġhas -1.236761\n",
      "5        Ġa -0.538658\n",
      "6     Ġcall -4.164424\n",
      "7   Ġnumber -3.439832\n",
      "8       Ġon -1.361023\n",
      "9      Ġits -1.021375\n",
      "10   Ġspine -1.287340\n",
      "11       Ġ. -3.513690\n",
      "\n",
      "        prob     word\n",
      "0  -3.225354     each\n",
      "1  -3.874274      non\n",
      "2  -5.236221  fiction\n",
      "3  -0.472252     book\n",
      "4  -1.158080      has\n",
      "5  -0.485143        a\n",
      "6  -3.748181     call\n",
      "7  -2.511031   number\n",
      "8  -1.469794       in\n",
      "9  -1.263469      its\n",
      "10 -2.077428    spine\n",
      "        word      prob\n",
      "0       Each -3.225354\n",
      "1       Ġnon -3.874274\n",
      "2   Ġfiction -5.236221\n",
      "3      Ġbook -0.472252\n",
      "4       Ġhas -1.158080\n",
      "5         Ġa -0.485143\n",
      "6      Ġcall -3.748181\n",
      "7    Ġnumber -2.511031\n",
      "8        Ġin -1.469794\n",
      "9       Ġits -1.263469\n",
      "10    Ġspine -2.077428\n",
      "11        Ġ. -3.149267\n",
      "\n",
      "       prob        word\n",
      "0 -0.558048        each\n",
      "1 -4.075552  nonfiction\n",
      "2 -1.725674        book\n",
      "3 -2.341121         had\n",
      "4 -0.017710           a\n",
      "5 -2.929285        call\n",
      "6 -1.819968      number\n",
      "7 -0.030658          on\n",
      "8 -0.462256         its\n",
      "9 -1.658430       spine\n",
      "          word      prob\n",
      "0         each -0.558048\n",
      "1   nonfiction -4.075552\n",
      "2         book -1.725674\n",
      "3          had -2.341121\n",
      "4            a -0.017710\n",
      "5         call -2.929285\n",
      "6       number -1.819968\n",
      "7           on -0.030658\n",
      "8          its -0.462256\n",
      "9        spine -1.658430\n",
      "10           . -0.004681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure correctness of this sub-sample?\n",
    "\n",
    "for idx, name in enumerate(transformer_names):\n",
    "    print(lm[f'{name}_scores'][idx])\n",
    "    print(temp_results[name][idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.403163</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.549038</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.950157</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.287342</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.303025</td>\n",
       "      <td>behind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.651266</td>\n",
       "      <td>him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.327117</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.748366</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.311556</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob    word\n",
       "0 -4.403163  austin\n",
       "1 -4.549038  closed\n",
       "2 -0.950157     the\n",
       "3 -1.287342    door\n",
       "4 -2.303025  behind\n",
       "5 -0.651266     him\n",
       "6 -1.327117      on\n",
       "7 -0.748366     the\n",
       "8 -3.311556    boat"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why does \"closed\" not match expectations?\n",
    "\n",
    "importlib.reload(align_prep_words)\n",
    "align_prep_words.process_nan_single_df(temp_results['gpt2_normal'][1260], tokenizers['gpt2'], word_list[1260])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More scratchwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import load_runs\n",
    "\n",
    "agg_all_runs = load_runs.load_runs()\n",
    "prep_all_runs = pd.read_csv('output/all_runs.csv')\n",
    "\n",
    "\n",
    "prep_list = list(prep_all_runs['user_candidate_transcription'])\n",
    "agg_list = list(agg_all_runs['user_candidate_transcription'])\n",
    "\n",
    "# They seem to be the same sentences, but in different orders.\n",
    "\n",
    "print(set(prep_list) ^ set(agg_list))\n",
    "print(prep_list[1:] == agg_list[1:])\n",
    "\n",
    "print(sorted(prep_list) == sorted(agg_list)) # They are just in different orders. So it should be fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to filter out all of the words that don't align? But how?\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "DATA_PREP_FOLDER = './intermediate_results/data_prep_logistic'\n",
    "\n",
    "model_names = [filename.split('logistic/')[1].split('_predictions.txt')[0]\n",
    "               for filename in glob.glob(DATA_PREP_FOLDER+'/*')]\n",
    "\n",
    "lm = {}\n",
    "\n",
    "for lm_name in model_names:\n",
    "    raw_scores_path = join(DATA_PREP_FOLDER, f\"{lm_name}_predictions.txt\")\n",
    "    # 3/27: https://stackoverflow.com/questions/27745500/how-to-save-a-list-to-a-file-and-read-it-as-a-list-type\n",
    "    with open(raw_scores_path, 'rb') as f:\n",
    "        raw_scores = pickle.load(f)\n",
    "        lm[lm_name] = raw_scores\n",
    "        \n",
    "BERT_case = 'A dietitian goes'\n",
    "GPT_case = 'Each nonfiction book'\n",
    "\n",
    "tokenizers['bert'].tokenize(BERT_case)\n",
    "tokenizers['gpt2'].tokenize(GPT_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is verified\n",
    "\n",
    "word_list = [df['word'].values.tolist() for df in lm['bnc_unigram']]\n",
    "result = align_prep_words.align_model_word_dfs(lm['gpt2_normal_scores'][:2], tokenizers['gpt2'], word_list[:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word      prob\n",
      "0      Each -3.570354\n",
      "1      Ġnon -3.581758\n",
      "2   fiction -1.928502\n",
      "3     Ġbook -0.357789\n",
      "4      Ġhas -1.236761\n",
      "5        Ġa -0.538658\n",
      "6     Ġcall -4.164424\n",
      "7   Ġnumber -3.439832\n",
      "8       Ġon -1.361023\n",
      "9      Ġits -1.021375\n",
      "10   Ġspine -1.287340\n",
      "11       Ġ. -3.513690\n",
      "entire idx 1 to collapse 1\n",
      "entire word nonfiction\n",
      "to collapse idx non\n",
      "\t Next collapse: 3\n",
      "\n",
      "       prob        word\n",
      "0 -3.570354        each\n",
      "1       NaN  nonfiction\n",
      "2 -0.357789        book\n",
      "3 -1.236761         has\n",
      "4 -0.538658           a\n",
      "5 -4.164424        call\n",
      "6 -3.439832      number\n",
      "7 -1.361023          on\n",
      "8 -1.021375         its\n",
      "9 -1.287340       spine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def test_bert_dietitian():\n",
    "    test_idx = 18\n",
    "\n",
    "    orig_score = lm['bert_scores'][test_idx]\n",
    "\n",
    "    print(orig_score)\n",
    "\n",
    "    reference_sentence = 'a dietitian goes to college for at least four years'\n",
    "    result = process_nan_single_df(lm['bert_scores'][test_idx], tokenizers['bert'], reference_sentence)\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "def test_gpt2_nonfiction():\n",
    "    \n",
    "    test_idx = 0\n",
    "\n",
    "    orig_score = lm['gpt2_normal_scores'][test_idx]\n",
    "\n",
    "    print(orig_score)\n",
    "\n",
    "    reference_sentence = 'each nonfiction book has a call number on its spine'\n",
    "    result = process_nan_single_df(lm['gpt2_normal_scores'][test_idx], tokenizers['gpt2'], reference_sentence)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    \n",
    "test_gpt2_nonfiction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.124584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diet</td>\n",
       "      <td>-0.714438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##itia</td>\n",
       "      <td>-0.188612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##n</td>\n",
       "      <td>-0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goes</td>\n",
       "      <td>-0.189202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>-0.074309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college</td>\n",
       "      <td>-1.313672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>-0.032421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at</td>\n",
       "      <td>-0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>least</td>\n",
       "      <td>-0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>four</td>\n",
       "      <td>-0.853766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>years</td>\n",
       "      <td>-0.015433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.</td>\n",
       "      <td>-0.003171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      prob\n",
       "0         a -0.124584\n",
       "1      diet -0.714438\n",
       "2    ##itia -0.188612\n",
       "3       ##n -0.046200\n",
       "4      goes -0.189202\n",
       "5        to -0.074309\n",
       "6   college -1.313672\n",
       "7       for -0.032421\n",
       "8        at -0.000133\n",
       "9     least -0.000926\n",
       "10     four -0.853766\n",
       "11    years -0.015433\n",
       "12        . -0.003171"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_results['bert'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Each</td>\n",
       "      <td>-3.225354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ġnon</td>\n",
       "      <td>-3.874274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ġfiction</td>\n",
       "      <td>-5.236221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ġbook</td>\n",
       "      <td>-0.472252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ġhas</td>\n",
       "      <td>-1.158080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ġa</td>\n",
       "      <td>-0.485143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ġcall</td>\n",
       "      <td>-3.748181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ġnumber</td>\n",
       "      <td>-2.511031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ġin</td>\n",
       "      <td>-1.469794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ġits</td>\n",
       "      <td>-1.263469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ġspine</td>\n",
       "      <td>-2.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ġ.</td>\n",
       "      <td>-3.149267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      prob\n",
       "0       Each -3.225354\n",
       "1       Ġnon -3.874274\n",
       "2   Ġfiction -5.236221\n",
       "3      Ġbook -0.472252\n",
       "4       Ġhas -1.158080\n",
       "5         Ġa -0.485143\n",
       "6      Ġcall -3.748181\n",
       "7    Ġnumber -2.511031\n",
       "8        Ġin -1.469794\n",
       "9       Ġits -1.263469\n",
       "10    Ġspine -2.077428\n",
       "11        Ġ. -3.149267"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_results['gpt2_medium'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_find_next_word_bert():\n",
    "    \n",
    "    reference_sentence = 'a dietitian goes to college for at least four years'\n",
    "    \n",
    "    tok = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n",
    "    ttokens = [filter_symbols(t) for t in tok.tokenize(reference_sentence)]\n",
    "    tidx = find_next_word_loc(1, ttokens, 'dietitian')\n",
    "    \n",
    "    assert tidx == 4 \n",
    "    \n",
    "def test_find_next_word_gpt2():\n",
    "    \n",
    "    reference_sentence = 'each nonfiction book has a call number on its spine'\n",
    "    tok = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    ttokens = [filter_symbols(t) for t in tok.tokenize(reference_sentence)]\n",
    "    tidx = find_next_word_loc(1, ttokens, 'nonfiction')\n",
    "    \n",
    "    assert tidx == 3\n",
    "\n",
    "test_find_next_word_bert()\n",
    "test_find_next_word_gpt2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: Index 1\n",
      "\t['each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', 'in', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', 'in', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach non fiction book has a call number in its spine\n",
      "a\n",
      "reference: Index 2\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had a call number on its spine\n",
      "a\n",
      "reference: Index 3\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had a call number on its spine\n",
      "a\n",
      "reference: Index 4\n",
      "\t['each', 'non', 'fiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'non', 'fiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach non fiction book had a call number on its spine\n",
      "a\n",
      "reference: Index 5\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had a call number on its spine\n",
      "a\n",
      "reference: Index 6\n",
      "\t['each', 'non', 'fiction', 'book', 'had', '12', 'numbers', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'non', 'fiction', 'book', 'had', '12', 'numbers', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach non fiction book had 12 numbers on its spine\n",
      "a\n",
      "reference: Index 7\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'numbers', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'numbers', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had twelve numbers on its spine\n",
      "a\n",
      "reference: Index 8\n",
      "\t['each', 'non', 'fiction', 'book', 'had', 'twelve', 'numbers', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'non', 'fiction', 'book', 'had', 'twelve', 'numbers', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach non fiction book had twelve numbers on its spine\n",
      "a\n",
      "reference: Index 9\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'notches', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'notch', '##es', 'on', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had twelve notches on its spine\n",
      "a\n",
      "reference: Index 10\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'notches', 'in', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['each', 'nonfiction', 'book', 'had', 'twelve', 'notch', '##es', 'in', 'its', 'spine', '.']\n",
      "csv\n",
      "\teach nonfiction book had twelve notches in its spine\n",
      "a\n",
      "reference: Index 11\n",
      "\t['which', 'non', 'fiction', 'book', 'would', 'you', 'want', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'non', 'fiction', 'book', 'would', 'you', 'want', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich non fiction book would you want to read\n",
      "\n",
      "reference: Index 12\n",
      "\t['which', 'nonfiction', 'book', 'would', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'nonfiction', 'book', 'would', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich nonfiction book would you like to read\n",
      "a\n",
      "reference: Index 13\n",
      "\t['which', 'nonfiction', 'book', 'do', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'nonfiction', 'book', 'do', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich nonfiction book do you like to read\n",
      "a\n",
      "reference: Index 14\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich non fiction book do you like to read\n",
      "a\n",
      "reference: Index 15\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich non fiction book do you like to read\n",
      "a\n",
      "reference: Index 16\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich non fiction book do you like to read\n",
      "a\n",
      "reference: Index 17\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '</s>']\n",
      "actual\n",
      "\t['which', 'non', 'fiction', 'book', 'do', 'you', 'like', 'to', 'read', '.']\n",
      "csv\n",
      "\twhich non fiction book do you like to read\n",
      "a\n",
      "reference: Index 18\n",
      "\t['each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['a', 'diet', '##itia', '##n', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.']\n",
      "csv\n",
      "\teach nonfiction book has a call number on its spine\n",
      "s\n",
      "reference: Index 19\n",
      "\t['each', 'non', 'fiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['a', 'diet', '##itia', '##n', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.']\n",
      "csv\n",
      "\teach non fiction book has a call number on its spine\n",
      "s\n",
      "reference: Index 20\n",
      "\t['each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['a', 'priest', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.']\n",
      "csv\n",
      "\teach nonfiction book has a call number on its spine\n",
      "s\n",
      "reference: Index 21\n",
      "\t['each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['a', 'priest', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.']\n",
      "csv\n",
      "\teach nonfiction book has a call number on its spine\n",
      "s\n",
      "reference: Index 22\n",
      "\t['each', 'nonfiction', 'book', 'has', 'a', 'call', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['the', 'priest', 'goes', 'to', 'college', 'for', 'at', 'least', 'four', 'years', '.']\n",
      "csv\n",
      "\teach nonfiction book has a call number on its spine\n",
      "s\n",
      "reference: Index 23\n",
      "\t['each', 'call', 'section', 'book', 'has', 'a', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['the', 'fruits', 'lose', 'their', 'color', 'for', 'at', 'least', 'four', 'winters', '.']\n",
      "csv\n",
      "\teach call section book has a number on its spine\n",
      "s\n",
      "reference: Index 24\n",
      "\t['each', 'call', 'that', 'you', 'book', 'has', 'a', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['the', 'horses', 'have', 'color', 'for', 'at', 'least', 'four', 'winters', '.']\n",
      "csv\n",
      "\teach call that you book has a number on its spine\n",
      "s\n",
      "reference: Index 25\n",
      "\t['its', 'called', 'an', 'easel', 'and', 'has', 'a', 'number', 'on', 'its', 'spine', '</s>']\n",
      "actual\n",
      "\t['the', 'horses', 'are', 'colorful', 'and', 'many', 'have', 'flu', '##ff', '.']\n",
      "csv\n",
      "\tits called an easel and has a number on its spine\n",
      "s\n",
      "reference: Index 26\n",
      "\t['it', 'is', 'called', 'an', 'easel', 'and', 'its', 'number', 'and', 'it', 'is', 'fine', '</s>']\n",
      "actual\n",
      "\t['the', 'horses', 'are', 'colorful', 'and', 'many', 'have', 'flu', '##ff', '.']\n",
      "csv\n",
      "\tit is called an easel and its number and it is fine\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "# all_runs and BERT scores are not aligned?\n",
    "for i, sent_ref in enumerate(lm['bnc_unigram']):\n",
    "    \n",
    "    if i == 0 : continue \n",
    "        \n",
    "    sent_act = lm['bert_scores'][i] \n",
    "    \n",
    "    print(f'reference: Index {i}')\n",
    "    print(f'\\t{list(sent_ref[\"word\"])}')\n",
    "    print('actual')\n",
    "    print(f'\\t{list(sent_act[\"word\"])}')\n",
    "    print('csv')\n",
    "    print(f'\\t{all_entire_word_reference[i]}')\n",
    "    a = input()\n",
    "    if a == 'quit':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 0\n",
      "It 0.00911561120301485\n",
      "'s 0.4054446220397949\n",
      "Ġtime 0.034498848021030426\n",
      "Ġto 0.548720121383667\n",
      "Ġgo 0.015521024353802204\n",
      "Ġto 0.08927261829376221\n",
      "Ġthe 0.1976589858531952\n",
      "Ġstore 0.019540343433618546\n",
      "Ġ. 0.0002333719312446192\n",
      "<|endoftext|> 0.004117126576602459\n",
      "Walk 3.4847416827687994e-05\n",
      "Ġslowly 0.00015021645231172442\n",
      "Ġto 0.03525398299098015\n",
      "Ġthe 0.47555652260780334\n",
      "Ġgolden 4.06051694881171e-05\n",
      "Ġstair 0.006223683711141348\n",
      "Ġ. 3.163226574542932e-05\n",
      "<|endoftext|> 0.0008614695398136973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            word      prob\n",
       " 0             It  0.009116\n",
       " 1             's  0.405445\n",
       " 2          Ġtime  0.034499\n",
       " 3            Ġto  0.548720\n",
       " 4            Ġgo  0.015521\n",
       " 5            Ġto  0.089273\n",
       " 6           Ġthe  0.197659\n",
       " 7         Ġstore  0.019540\n",
       " 8             Ġ.  0.000233\n",
       " 9  <|endoftext|>  0.004117,             word      prob\n",
       " 0           Walk  0.000035\n",
       " 1        Ġslowly  0.000150\n",
       " 2            Ġto  0.035254\n",
       " 3           Ġthe  0.475557\n",
       " 4        Ġgolden  0.000041\n",
       " 5         Ġstair  0.006224\n",
       " 6             Ġ.  0.000032\n",
       " 7  <|endoftext|>  0.000861]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import new_models\n",
    "from new_models import model_score_funcs\n",
    "\n",
    "\n",
    "import importlib\n",
    "importlib.reload(model_score_funcs)\n",
    "\n",
    "\n",
    "inputs = [\n",
    "    \"it's time to go to the store\",\n",
    "    \"walk slowly to the golden stair\"\n",
    "]\n",
    "\n",
    "model_score_funcs.get_gpt2_scores(inputs)\n",
    "#model_score_funcs.get_bert_scores(inputs)\n",
    "#model_score_funcs.get_bart_scores(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_bertlike_model_probs() missing 1 required positional argument: 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-8a5b3b0e6cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mbert_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_bertlike_model_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test_bertlike_model_probs() missing 1 required positional argument: 'model_name'"
     ]
    }
   ],
   "source": [
    "## Testing the next model probabilities\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from new_models import model_score_utils\n",
    "\n",
    "importlib.reload(model_score_utils)\n",
    "\n",
    "\n",
    "def report_mask_words(scores, sentence, tokenizer):\n",
    "    \"\"\"\n",
    "    raw_scores = a (vocabulary,) tensor of selected softmax values for a pre-selected position.\n",
    "    mask_idx, the position to select for analysis.\n",
    "    \n",
    "    sentence = the prefix to do the prediction on\n",
    "    tokenizer = BERT/BART tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # It should intake the raw scores itself.\n",
    "    score_vals, word_idxs = torch.sort(scores, descending = True)\n",
    "    words = tokenizer.convert_ids_to_tokens(word_idxs)\n",
    "\n",
    "    print(f\"Reporting most likely tokens to complete '{sentence}' in descending order\")\n",
    "\n",
    "    num_report = 20\n",
    "\n",
    "    score_df = pd.DataFrame.from_dict({\n",
    "      'Word': words,\n",
    "      'Score value': list(map(lambda x : round(x, 5), score_vals.numpy().tolist()))\n",
    "      })\n",
    "\n",
    "    return score_df[:num_report]\n",
    "\n",
    "\n",
    "def test_gpt2_model_probs():\n",
    "    \n",
    "    \n",
    "    print('Note that this outputs softmax of the last word before the punctuation.')\n",
    "    \n",
    "    model = models['gpt2']; tok = tokenizers['gpt2']\n",
    "    test_sentence = \"it's time to go to the\"\n",
    "    # Below line is from the prefix code\n",
    "    test_sentence = f'{tok.bos_token}{test_sentence}{tok.eos_token}'\n",
    "    \n",
    "    this_tokens = tok.encode(test_sentence)\n",
    "    \n",
    "    # The 0 is a filler index.\n",
    "    this_pred_pos = len(this_tokens) - 2\n",
    "    _, probs = model_score_utils.get_model_probabilities(this_tokens, model, 0, this_pred_pos, verifying = True)\n",
    "    result_df = report_mask_words(probs, test_sentence, tok)\n",
    "    \n",
    "    test_word = 'Ġbathroom'\n",
    "    ground_truth_token = tok.convert_tokens_to_ids(test_word)\n",
    "    \n",
    "    print(f'Ground truth probability, manual extract, for the word {test_word}: {probs[ground_truth_token]}')\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "    \n",
    "def test_bertlike_model_probs(test_sentence, model_name):\n",
    "        \n",
    "    model = models[model_name]; tok = tokenizers[model_name]\n",
    "    \n",
    "    test_sentence = f\"it's time to go to the {tok.mask_token}\"\n",
    "    this_tokens = tok.encode(test_sentence)\n",
    "    this_pred_pos = len(this_tokens) - 2\n",
    "    \n",
    "    # The 0 is a filler index.\n",
    "    prob_at_ground_truth, probs = model_score_utils.get_model_probabilities(this_tokens, model, 0, this_pred_pos, verifying = True)\n",
    "\n",
    "    # For the ground truth idx? How to test this? Do it by cross-checking it with the probs in the \"most likely\".\n",
    "    result_df = report_mask_words(probs, test_sentence, tok)\n",
    "\n",
    "    test_word = 'moon' if model_name == 'bert' else 'Ġstore'\n",
    "    ground_truth_token = tok.convert_tokens_to_ids(test_word)\n",
    "    \n",
    "    print(f'Ground truth probability, manual extract, for the word {test_word}: {probs[ground_truth_token]}')\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "bert_df = test_bertlike_model_probs('bert')\n",
    "print(bert_df)\n",
    "\n",
    "#bart_df = test_bertlike_model_probs('bart')\n",
    "#print(bart_df)\n",
    "\n",
    "#gpt2_df = test_gpt2_model_probs()\n",
    "#print(gpt2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is updated\n",
      "[ M A S K ]\n",
      "Reporting most likely tokens to complete 'each nonfiction book had a call number on its spine' in descending order\n",
      "          Word  Score value\n",
      "0        first      0.29029\n",
      "1         last      0.15535\n",
      "2        final      0.07602\n",
      "3       second      0.05278\n",
      "4          top      0.03681\n",
      "5        third      0.02572\n",
      "6         next      0.01916\n",
      "7        fifth      0.01754\n",
      "8       bottom      0.01634\n",
      "9      seventh      0.01319\n",
      "10      fourth      0.01292\n",
      "11        main      0.01015\n",
      "12       front      0.00830\n",
      "13      eighth      0.00811\n",
      "14      spiral      0.00801\n",
      "15      lowest      0.00776\n",
      "16        back      0.00671\n",
      "17       tenth      0.00656\n",
      "18  thirteenth      0.00527\n",
      "19       ninth      0.00514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tok = tokenizers['bert']\n",
    "\n",
    "# {tok.mask_token} nonfiction book had a call number on its spine\n",
    "this_test = f'walk slowly to the {tok.mask_token} stair'\n",
    "this_tokens = tokenizers['bert'].encode(this_test)\n",
    "\n",
    "pred_idx = 5\n",
    "prob_at_ground_truth, probs = model_score_utils.get_model_probabilities(this_tokens, models['bert'], 0, pred_idx, verifying = True)\n",
    "\n",
    "print(tok.decode(this_tokens[pred_idx]))\n",
    "\n",
    "# For the ground truth idx? How to test this? Do it by cross-checking it with the probs in the \"most likely\".\n",
    "result_df = report_mask_words(probs, test_sentence, tokenizers['bert'])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 checks\n",
      "['<|endoftext|>']\n",
      "['<|endoftext|>', 'each']\n",
      "['<|endoftext|>', 'each', 'Ġnon']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits']\n",
      "['<|endoftext|>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine']\n",
      "\n",
      "BERT checks\n",
      "['[CLS]', '[MASK]', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', '[MASK]', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', '[MASK]', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', '[MASK]', 'a', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', '[MASK]', 'call', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', '[MASK]', 'number', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', '[MASK]', 'on', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', '[MASK]', 'its', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', '[MASK]', 'spine', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', '[MASK]', '[SEP]']\n",
      "['[CLS]', 'each', 'nonfiction', 'book', 'had', 'a', 'call', 'number', 'on', 'its', 'spine', '[MASK]']\n",
      "\n",
      "BART checks\n",
      "['<s>', '<mask>', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', '<mask>', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', '<mask>', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', '<mask>', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', '<mask>', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', '<mask>', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', '<mask>', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', '<mask>', 'Ġon', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', '<mask>', 'Ġits', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', '<mask>', 'Ġspine', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', '<mask>', '</s>']\n",
      "['<s>', 'each', 'Ġnon', 'fiction', 'Ġbook', 'Ġhad', 'Ġa', 'Ġcall', 'Ġnumber', 'Ġon', 'Ġits', 'Ġspine', '<mask>']\n"
     ]
    }
   ],
   "source": [
    "## Testing the model prefixes functions\n",
    "\n",
    "\n",
    "from new_models import model_prefixes\n",
    "\n",
    "import importlib\n",
    "importlib.reload(model_prefixes)\n",
    "\n",
    "\n",
    "test_sentence = \"It's time to go to the store.\"\n",
    "    \n",
    "def test_gpt2_prefixes(s):\n",
    "    tok = tokenizers['gpt2']\n",
    "    prefixes, _ = model_prefixes.get_gpt2_prefixes(s, tok)\n",
    "    for p in prefixes:\n",
    "        print(tok.convert_ids_to_tokens(p))\n",
    "        \n",
    "def test_bertlike_prefixes(s, model_name):\n",
    "    \n",
    "    tok = tokenizers[model_name]\n",
    "    mask_func = model_prefixes.get_bertlike_mask_func(tok)\n",
    "    \n",
    "    prefixes, _ = mask_func(s, tok)\n",
    "    for p in prefixes:\n",
    "        print(tok.convert_ids_to_tokens(p))\n",
    "\n",
    "test_sentence = \"each nonfiction book had a call number on its spine\"\n",
    "print('GPT2 checks')\n",
    "test_gpt2_prefixes(test_sentence)\n",
    "print('\\nBERT checks')\n",
    "test_bertlike_prefixes(test_sentence, 'bert')\n",
    "print('\\nBART checks')\n",
    "test_bertlike_prefixes(test_sentence, 'bart')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telephone-env-3",
   "language": "python",
   "name": "telephone-env-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
