{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for GPT-2 scratchwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dev_csv_path = './dev_lm_sentence_input.csv'\n",
    "\n",
    "all_sentences = pd.read_csv(dev_csv_path)['user_candidate_transcription']\n",
    "print(len(all_sentences))\n",
    "num_select = 2\n",
    "sentences_subset = list(all_sentences.iloc[:num_select])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_model_funcs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b79c1c3e2e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpt2_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubset_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/gpt2_scores.py\u001b[0m in \u001b[0;36mscore_sentences\u001b[0;34m(sentences, model_type, verbose)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0msentence_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_gpt2_sentence_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/gpt2_scores.py\u001b[0m in \u001b[0;36mget_gpt2_sentence_score\u001b[0;34m(sentence, tokenizer, model)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mthis_surprisal_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model_funcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_word_surprisal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_next_word_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_ground_truth_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mthis_sum_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_surprisal_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This will be averaged in the main ipynb analysis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthis_sum_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_model_funcs' is not defined"
     ]
    }
   ],
   "source": [
    "import gpt2_scores\n",
    "subset_scores = gpt2_scores.score_sentences(sentences_subset, model_type = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'new_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d43c68ca3a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_prefix_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"spec not found for the module {name!r}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/telephone-env-3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/home/nwong/chompsky/serial_chain/telephone-analysis-public/new_models/bert_prefix_scores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnew_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnew_model_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnew_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_model_funcs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'new_models'"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "import bert_prefix_scores\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "# 3/11: importlib help: https://stackoverflow.com/questions/1254370/reimport-a-module-in-python-while-interactive\n",
    "\n",
    "import importlib\n",
    "importlib.reload(bert_prefix_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# General sanity checks for trends -- the trends don't completely match up with expectation,\n",
    "#   but the ones with obvious differences (okay sentence structure vs. bad structure) do.\n",
    "sentence_cases = [\n",
    "    'apple toast bring not unsure test coding', # Should have high surprisal\n",
    "    'the person walked down the street', # Low surprisal\n",
    "    'I did not want to go to the library dolphin', # Should have medium surprisal due to last word.\n",
    "    'I would have preferred to eat libraries', # Should have medium surprisal due to last word.\n",
    "    'I coding test passed consequently did yes', # Should have high surprisal\n",
    "    'this sentence should have a low score', # Low surprisal (or medium after observing the results, because \"score\" is ML-specific)\n",
    "    'this sentence should have a paragraph', # Even lower surprisal -- observationally this isn't the case! Which is interesting.\n",
    "]\n",
    "\n",
    "# These results aren't really intuitive.\n",
    "\n",
    "results = bert_prefix_scores.score_sentences(sentence_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sentence apple toast bring not unsure test coding\n",
      "\tThe surprisal per word was 11.624098641531807\n",
      "For sentence the person walked down the street\n",
      "\tThe surprisal per word was 2.7322870890299478\n",
      "For sentence I did not want to go to the library dolphin\n",
      "\tThe surprisal per word was 3.110466194152832\n",
      "For sentence I would have preferred to eat libraries\n",
      "\tThe surprisal per word was 3.859767641339983\n",
      "For sentence I coding test passed consequently did yes\n",
      "\tThe surprisal per word was 10.099221365792411\n",
      "For sentence this sentence should have a low score\n",
      "\tThe surprisal per word was 3.726261411394392\n",
      "For sentence this sentence should have a paragraph\n",
      "\tThe surprisal per word was 4.932441711425781\n"
     ]
    }
   ],
   "source": [
    "for s, score in zip(sentence_cases, results):\n",
    "    print(f'For sentence {s}')\n",
    "    print(f'\\tThe surprisal per word was {score / len(s.split())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "## More informal checks of correctness in BERT\n",
    "import torch\n",
    "\n",
    "#2/20: https://huggingface.co/transformers/quickstart.html\n",
    "\n",
    "# Please note that, for consistency with the standard \"It's time to go to the\" check, I use bert-base-uncased here.\n",
    "# But the actual model used for the tests is the word tokenized one.\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "model.eval()\n",
    "    \n",
    "#2/20: https://albertauyeung.github.io/2020/06/19/bert-tokenization.html\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_positions_from_encoded():\n",
    "    \n",
    "    #2/20: https://albertauyeung.github.io/2020/06/19/bert-tokenization.html\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking\")\n",
    "\n",
    "    sent = \"This is great\"\n",
    "\n",
    "    enc_s, seg_s = bert_prefix_scores.get_encoded_text(sent, tokenizer)\n",
    "    res_tokens, res_segs, res_next_words = bert_prefix_scores.get_positions_from_encoded(enc_s, seg_s, 103)\n",
    "\n",
    "    expected = [\n",
    "        ['[CLS]', '[MASK]', 'is', 'great', '.', '[SEP]'],\n",
    "        ['[CLS]', 'this', '[MASK]', 'great', '.', '[SEP]'],\n",
    "        ['[CLS]', 'this', 'is', '[MASK]', '.', '[SEP]']\n",
    "    ]\n",
    "    \n",
    "    actual = decode_token_list(res_tokens)\n",
    "    assert actual == expected\n",
    "    \n",
    "test_get_positions_from_encoded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3/11: importlib help: https://stackoverflow.com/questions/1254370/reimport-a-module-in-python-while-interactive\n",
    "import importlib\n",
    "importlib.reload(bert_prefix_scores)\n",
    "\n",
    "import new_model_funcs\n",
    "\n",
    "def prefix_predictions_single(this_sentence):\n",
    "\n",
    "    score, this_probs = bert_prefix_scores.get_bert_sentence_score(this_sentence, tokenizer, model, verifying = True )\n",
    "\n",
    "    raw_tokens = tokenizer.tokenize(this_sentence)\n",
    "\n",
    "    words = sentence.split()\n",
    "    for idx in range(0, this_probs.shape[0]):\n",
    "        # Note that need to negate surprisals to treat them like probabilities, as here.\n",
    "        results, _ = bert_prefix_scores.report_mask_words(this_probs[idx], raw_tokens[:idx], tokenizer)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard sanity check\n",
    "#prefix_predictions_single(\"It's time to go to the store\") \n",
    "\n",
    "# Below: Trying to ensure that strange behavior\n",
    "#     on always choosing the ground truth as the highest next prediction is resolved.\n",
    "\n",
    "# 3/20: This is now fixed, there is no strange behavior.\n",
    "\n",
    "prefix_predictions_single(\"apple toast bring\")\n",
    "prefix_predictions_single(\"apple pie bring\")\n",
    "prefix_predictions_single(\"apple toast bring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gpt2_tests.py # These might have been broken by BERT development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telephone-env-3",
   "language": "python",
   "name": "telephone-env-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
